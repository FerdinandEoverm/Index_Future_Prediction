{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88bc4d21",
   "metadata": {},
   "source": [
    "Transformer及其衍生架构，在自然语言处理上取得了卓越的成果。但是，在将这一范式迁移到时间序列预测上来的时候，却遇到了尴尬的打不过线性模型的困难"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a60c2",
   "metadata": {},
   "source": [
    "首先我们分析一下，NLP（自然语言处理）和TSF（时间序列预测）两个问题的主要差别：\n",
    "\n",
    "1. 自然语言中的语义既存在在每个单词中，也存在在单词之间的序列关系上。一个句子完全打乱单词顺序，也能保留部分信息（尽管不那么准确）。一个还不懂语法的语言学习者，仅靠单词也可以和其他人勉强交流。但是对于时间序列，打乱顺序就意味着完全丢失信息，可以说时间序列的信息绝大部分都隐藏在序列之中。\n",
    "\n",
    "2. 自然语言的具有高度的一致性和可迁移性，常见单词和词组的含义在绝大多数语料中都是相近相似的，虽然会有一些多义词但毕竟是少数。而不同的时间序列即使出现了相同的形态，也不能说就有相似含义。例如，在金融领域，某些价格形态会包含价格趋势信息，其底层的逻辑是多空双方的博弈导致的，但是如果这样的形态出现在例如气温序列中，就不能说表示趋势性，因为底层的逻辑完全不一样。\n",
    "\n",
    "3. 自然语言的训练集非常丰富，在人类历史上积累了大量的训练语料。但由于时间序列的含义差距，每个领域的时间序列是有限的，只能使用当前研究的框架内的数据。一般资产的数据有10年以上已经是非常丰富的历史了。如果扩展序列就会面临结构和范式的变化。\n",
    "\n",
    "4. 自然语言的模式迁移非常缓慢，几乎可以忽略不记，虽然人类的语言会有所发展和变化，但是这种变化都是以数十年为单位的，在短期内改变的只会有少数词的词义，大的语法是不会改变的。但对于金融数据。概念漂移是非常常见的，时间序列的底层因素，例如次贷危机、疫情的出现很可能直接导致资产的模式完全改变，从而让历史数据的价值大打折扣，进一步加剧了数据量的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c3e3f",
   "metadata": {},
   "source": [
    "Transformer架构能在NLP上取得成功的原因，恰恰也是Transformer架构不能被直接迁移到TSF上的原因：\n",
    "\n",
    "1. RNN架构的顺序结构会影响长距离信息传递，长距离信息要么随着梯度消失，要么产生梯度爆炸。为了能顺利捕捉长距离关系，Transformer架构可以放弃了RNN架构的顺序性，转而使用并行性保护远距离信息可以顺利传播；\n",
    "\n",
    "2. 因为采用了并行架构丢失了顺序信息，Transformer架构采用位置编码补齐丢失的顺序信息。但位置编码会影响一部分原始语义信息；\n",
    "\n",
    "3. 因为训练语料足够丰富，导致位置编码的影响可以被最小化；\n",
    "\n",
    "4. 平行架构也可以充分运用算力，大幅度加速训练过程，因此可以接受更复杂的模型层数。将牺牲的部分通过更大的模型来弥补。\n",
    "\n",
    "换言之，因为自然语言的训练资料足够丰富，足以掩盖Transformer架构的缺点，充分发挥Transformer架构的优势，才使得Transformer架构得以在NLP问题上大放异彩。但反过来，在TSF问题上，Transformer架构并没有这样的优势。而其劣势，会被时间序列数据量缺乏的问题放大。Transformer架构本身就很复杂，模型的参数量越大，需要的数据集也就越大，超大的模型可以轻松记忆本就为数不多的数据集导致过拟合，必须对扩展模型保持谨慎态度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007329c",
   "metadata": {},
   "source": [
    "当然，这也并不意味着完全就不能使用Transformer架构。Transformer架构在长距离提取上仍然有优势。具体来说，如果想要充分发挥Transformer架构的优势，我们需要解决如下问题：\n",
    "\n",
    "1. 每个信息单元包含的信息要足够丰富。自然语言中每个单词的语义已经非常丰富，最新的的大语言模型单个词嵌入维度已经达到了4096甚至更高。而单个时间步的OHLCV数据的维度太小，即使扩展一些辅助信息，也很难从单个时间步得到有效信息进行相互传播。因此，单个信息单元要从时间步提升到子序列级别，比如一个长达10天的子序列，除了10天本身的价格信息以外，还能抽象出某种趋势信息，例如一小段缩量上涨、或者一小段区间的放量震荡等等。通过将多个时间步组合成一个patch的方式，模型可以变为处理一段一段的时间。同时，这样的结构也可以接入更长的历史窗口，绕开Transformer在注意力层的O(N^2)复杂度的限制。\n",
    "\n",
    "2. 用科学的方式扩展训练集，如果我们的目标是资产价格预测，那么至少训练集的范围可以扩展到其他金融资产，但不应该扩展到非金融的领域。因为价格的底层逻辑是供需关系、多空博弈。同时，还要增加额外的机制让模型理解不同资产之间的差距和联系，例如波动率、相关性、协整性等等。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3856689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('d:/future/Index_Future_Prediction')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import optuna\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler, Adam, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from utils import *\n",
    "from modules import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9c872",
   "metadata": {},
   "source": [
    "首先，把预测时的回望序列分为若干等长的子序列，称为patch。patch之间可以重叠，也可以不重叠。但如果希望patch能抽象短期小段有意义的趋势，不重叠的patch有可能会割断有意义的片段，假设选择patch size为8且不允许重叠，那么一个恰好发生在第6天到第10天的小波段趋势就会被隔断在两个patch内导致无法被识别。因此，通过控制步长stride参数，来允许patch重叠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66722ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesPatcher(nn.Module):\n",
    "    \"\"\"\n",
    "    将形状为 (*, seq_len, feature) 的tensor重塑为 (*, num_patch, patch_size, feature)，允许patch重叠\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patch_size, stride):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x) :\n",
    "        \"\"\"\n",
    "        num_patch = floor((seq_len - patch_size) / stride) + 1\n",
    "        \"\"\"\n",
    "        seq_len = x.shape[-2]\n",
    "        assert seq_len >= self.patch_size, 'patch_size 超过了序列长度'\n",
    "        patches = x.unfold(dimension=-2, size=self.patch_size, step=self.stride)\n",
    "        patches = patches.swapaxes(-1, -2)\n",
    "        patches = torch.flatten(patches, start_dim = -2)\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f718fbf",
   "metadata": {},
   "source": [
    "接下来通过projection把每个patch的信息投影到高维空间。旨在这个阶段，从各个patch内抽象出序列的特征，例如这个序列的趋势、震荡等市场信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95ba113d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchProjection(nn.Module):\n",
    "    def __init__(self, input_size, patch_size, d_model = 128, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        self.project = nn.Linear(input_size * patch_size, d_model) # 暂时只使用单层线性投影就够了 暂时不需要做太过深度的信息抽象，这个过程会交给Encoder去完成\n",
    "        self.pe = PositionalEncoding(d_model = d_model, dropout = dropout) # 最普通的transformer位置编码\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.project(x)\n",
    "        x = self.pe(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58caf620",
   "metadata": {},
   "source": [
    "MultiLayerEncoder 层是普通的transformer 层。在这里让不同的patch在时间序列上交换信息。\n",
    "\n",
    "重点是这里的self_supervised 自监督学习：\n",
    "\n",
    "通过控制mask ratio 参数，在每次输入的序列中随机选择一些patch置为0，（然后再通过投影矩阵和位置编码），等于整个序列中，一部分patch丢失掉了自己的信息；\n",
    "\n",
    "在经过encoder相互传递信息后，让这些patch尝试重建自己的信息\n",
    "\n",
    "细节点是由于patch是允许重叠的，被要求重建的patch有一部分信息在其上下文中，因此在encoder传递信息的时候，必须扩大mask的范围，来把这些包含信息的patch也遮蔽掉\n",
    "\n",
    "在这个过程中，模型需要学会在不同patch间传递对预测有价值的信息，而不必传递那些对预测没有关系的信息。\n",
    "\n",
    "最后通过重建层输出重建的序列，跟原序列进行mse loss的对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f3c757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patch_TST(nn.Module):\n",
    "    \"\"\"Patch Time Series Transformer\"\"\"\n",
    "    def __init__(self, input_size, seq_len, patch_size, stride, num_layer, num_head, d_model, masking_ratio, mask_expand_size, dropout_1, dropout_2, dropout_3):\n",
    "        super().__init__()\n",
    "        self.device = 'cuda:0'\n",
    "        self.input_size = input_size\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.masking_ratio = masking_ratio\n",
    "        self.mask_expand_size = mask_expand_size\n",
    "\n",
    "        self.num_patch = int(np.floor((seq_len - patch_size) / stride) + 1)\n",
    "\n",
    "        self.patch = TimeSeriesPatcher(patch_size, stride) # 首先经过patcher分成子序列\n",
    "\n",
    "        self.projection = PatchProjection(input_size, patch_size, d_model = d_model, dropout = dropout_1)\n",
    "\n",
    "        self.encoder = MultiLayerEncoder(dim_feature = d_model, dim_sequence = self.num_patch, num_enc_layer = num_layer, num_head = num_head, num_ffn_hidden = d_model*2, dropout = dropout_2)\n",
    "\n",
    "        self.reconstruction = nn.Linear(d_model, input_size * patch_size)\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Flatten(start_dim = -2),\n",
    "            nn.Linear(self.num_patch * d_model, self.num_patch * d_model),\n",
    "            nn.Dropout(dropout_3),\n",
    "            HybridDecoder(dim_state = self.num_patch * d_model, init_prob = [0.0,0.5,0.0])\n",
    "        )\n",
    "    \n",
    "    def self_supervised(self, x):\n",
    "        \"\"\"\n",
    "        自监督预训练\n",
    "        如果不允许patch重叠，正好被patch隔断的形态无法学习到。\n",
    "        允许patch重叠，则模型预训练的时候可以从前后patch偷看到信息。\n",
    "        需要用双重mask\n",
    "        target mask 是真正需要重建的patch\n",
    "        input mask 是target mask的扩展，根据系数向两侧扩展掩蔽范围。例如假如patch允许重叠50%，则向前后各多屏蔽一个patch就可以完全屏蔽掉信息。\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "        batch_size = x.shape[0]\n",
    "        noise = torch.rand(size=(batch_size, self.num_patch), device=device)\n",
    "        target_mask = noise < self.masking_ratio\n",
    "        \n",
    "        # 防止出现所有 patch 都没被 mask 的情况，至少 mask 一个随机选择一个 patch 进行 mask\n",
    "        if not target_mask.any(dim=1).all():\n",
    "            for i in range(batch_size):\n",
    "                if not target_mask[i].any():\n",
    "                    fallback_idx = torch.randint(0, self.num_patch, (1,)).item()\n",
    "                    target_mask[i, fallback_idx] = True\n",
    "\n",
    "        target_mask_float = target_mask.float().unsqueeze(1)\n",
    "        kernel_size = 2 * self.mask_expand_size + 1\n",
    "        kernel = torch.ones(1, 1, kernel_size, device=device)\n",
    "        padding = self.mask_expand_size\n",
    "        expanded_mask_float = F.conv1d(target_mask_float, kernel, padding=padding)\n",
    "        input_mask = (expanded_mask_float > 0).squeeze(1)\n",
    "\n",
    "\n",
    "        x_patched = self.patch(x)\n",
    "        reshape_mask = input_mask.unsqueeze(-1)\n",
    "        x_masked = torch.where(reshape_mask, 0.0, x_patched)\n",
    "        x_projected = self.projection(x_masked)\n",
    "        x_encodered = self.encoder(x_projected)\n",
    "        \n",
    "        x_pre_reconstruction = x_encodered[target_mask] # 仅关注target mask\n",
    "        x_reconstructed = self.reconstruction(x_pre_reconstruction)\n",
    "        x_target = x_patched[target_mask] # 仅关注target mask\n",
    "\n",
    "        return x_reconstructed, x_target\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播输出\"\"\"\n",
    "        x_patched = self.patch(x)\n",
    "        x_projected = self.projection(x_patched)\n",
    "        x_encodered = self.encoder(x_projected)\n",
    "        output = self.output(x_encodered)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8975a7db",
   "metadata": {},
   "source": [
    "后面就比较简单了，当模型预训练完成之后，只需要再接上forward中的hybrid output输出预测就可以了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274e9491",
   "metadata": {},
   "source": [
    "我们再从训练集中抽出一部分作为验证集，用optuna进行超参数调优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2107fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # 超参数\n",
    "    seq_len = trial.suggest_int(\"seq_len\", 60, 250)\n",
    "    patch_size = trial.suggest_int(\"patch_size\", 5, 30)\n",
    "\n",
    "    num_layer = trial.suggest_categorical('num_layer', [1, 2,3,4,5])\n",
    "    num_head = trial.suggest_categorical('num_head', [4,8,16])\n",
    "    d_model = trial.suggest_categorical('d_model', [32, 64, 128, 256])\n",
    "\n",
    "    dropout_1 = trial.suggest_float(\"dropout_1\", 0.0, 0.5)\n",
    "    dropout_2 = trial.suggest_float(\"dropout_2\", 0.0, 0.5)\n",
    "    dropout_3 = 0.2 # dropout 3 是控制输出层的，这里暂时用不到\n",
    "\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    mask_expand_size = trial.suggest_categorical('mask_expand_size', [1, 2, 3])\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.7, 1.0)\n",
    "\n",
    "    # 预训练目标 masking_ratio 和 stride 这两个超参数是比较特殊的，不能随机选择\n",
    "    masking_ratio = 0.2\n",
    "    stride = math.ceil(patch_size / (mask_expand_size + 1))\n",
    "    # 掩码的比例是人为规定的预训练难度，随机选择这个参数不公平\n",
    "    # 步长则关系到模型能从前后的序列中偷看到多少的的信息，对预训练也至关重要，不属于超参数调优的范围\n",
    "\n",
    "    # 提取数据\n",
    "    assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX', 'AU.SHF', 'JM.DCE','RB.SHF','HC.SHF', 'I.DCE', 'M.DCE', 'CF.ZCE',]\n",
    "    feature_columns = ['inday_chg_open','inday_chg_high','inday_chg_low','inday_chg_close','inday_chg_amplitude', 'ma_10','ma_26','ma_45','ma_90','ma_vol',]\n",
    "    label_columns = ['label_return','down_prob','middle_prob','up_prob']\n",
    "    feature = []\n",
    "    label = []\n",
    "    for asset_code in assets_list:\n",
    "        data = pd.read_csv(f'data/{asset_code}.csv')\n",
    "        data = data[data['trade_date'] < 20230901 ].copy() # 2023年9月以后的数据需要用于回测 不参与训练\n",
    "        feature.append(torch.tensor(data[feature_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "        label.append(torch.tensor(data[label_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "\n",
    "    feature = torch.stack(feature, dim = 1)\n",
    "    feature = feature.unfold(dimension = 0, size = seq_len, step = 1).transpose(2,3)\n",
    "\n",
    "    label = torch.stack(label, dim = 1)\n",
    "    label = label[seq_len-1:]\n",
    "\n",
    "    data = RandomLoader(feature, label)\n",
    "    train_loader, test_loader = data(batch_size=batch_size, slice_size=[0.75,0.2], balance=[True, True]) # 再抽取20% 的数据作为验证集\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    model = Patch_TST(input_size = 10,\n",
    "                    seq_len = seq_len,\n",
    "\n",
    "                    patch_size = patch_size,\n",
    "                    stride = stride,\n",
    "                    masking_ratio = masking_ratio,\n",
    "                    mask_expand_size = mask_expand_size,\n",
    "\n",
    "                    num_layer = num_layer, \n",
    "                    num_head = num_head,\n",
    "                    d_model = d_model,\n",
    "\n",
    "                    dropout_1 = dropout_1,\n",
    "                    dropout_2 = dropout_2,\n",
    "                    dropout_3 = dropout_3,\n",
    "                    ).to('cuda:0')\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "    def epoch():\n",
    "        train_losses = []\n",
    "        model.train()\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x_reconstructed, x_target = model.self_supervised(batch_x)\n",
    "            loss = loss_fn(x_reconstructed, x_target)\n",
    "            train_losses.append(loss.item()) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        test_losses = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in test_loader:\n",
    "                x_reconstructed, x_target = model.self_supervised(batch_x)\n",
    "                loss = loss_fn(x_reconstructed, x_target)\n",
    "                test_losses.append(loss.item()) \n",
    "        return np.mean(train_losses), np.mean(test_losses)\n",
    "\n",
    "    def train(epochs = 30):\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        for i in tqdm.tqdm(range(epochs)):\n",
    "            train_loss, test_loss = epoch()\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            scheduler.step()\n",
    "        # plt.plot(range(epochs), train_losses)\n",
    "        # plt.plot(range(epochs), test_losses)\n",
    "        # plt.show()\n",
    "        return np.mean(test_losses[-10:])\n",
    "\n",
    "    final_loss = train(30)\n",
    "\n",
    "    return final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70dc0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(\n",
    "#     direction=\"minimize\",\n",
    "#     study_name=\"patchtst_pretrain_all\",\n",
    "#     storage=\"sqlite:///data/db.sqlite3_pretrain_all\",  # 保存到 SQLite 文件\n",
    "#     load_if_exists=True # 如果存在同名study，则加载它\n",
    "# )\n",
    "# study.optimize(objective, n_trials=30)\n",
    "\n",
    "\n",
    "# print(\"最佳试验的编号: \", study.best_trial.number)\n",
    "# print(\"最佳loss: \", study.best_value)\n",
    "# print(\"最佳超参数: \", study.best_params)\n",
    "# df = study.trials_dataframe()\n",
    "# df.sort_values(by='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1199c244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = optuna.visualization.plot_optimization_history(study)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36304473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = optuna.visualization.plot_param_importances(study)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40656da4",
   "metadata": {},
   "source": [
    "调优结果："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebec6d",
   "metadata": {},
   "source": [
    "在采用MSE Loss的时候：\n",
    "\n",
    "最佳loss:  1.0062134118967279 (MSELoss)\n",
    "\n",
    "最佳超参数:  {'seq_len': 111, 'patch_size': 5, 'num_layer': 2, 'num_head': 16, 'd_model': 128, 'dropout_1': 0.18965831923308327, 'dropout_2': 0.1430970459619855, 'batch_size': 64, 'learning_rate': 0.001439252094023002, 'weight_decay': 2.0667123273384227e-06, 'mask_expand_size': 1, 'gamma': 0.9810991631410341}\n",
    "\n",
    "该参数组的的MAE Loss:  0.5403792085367092 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdd3633",
   "metadata": {},
   "source": [
    "在采用MAE Loss的时候：\n",
    "\n",
    "最佳loss:  0.560926734309557\n",
    "\n",
    "最佳超参数:  {'seq_len': 99, 'patch_size': 8, 'num_layer': 3, 'num_head': 16, 'd_model': 256, 'dropout_1': 0.45461463067996066, 'dropout_2': 0.3853233951196199, 'batch_size': 32, 'learning_rate': 0.001615257095302926, 'weight_decay': 3.5940297438123993e-06, 'mask_expand_size': 1, 'gamma': 0.8462706280335419}\n",
    "\n",
    "该参数组的的MSE Loss:  1.025522967231901"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850030b3",
   "metadata": {},
   "source": [
    "可以看到，采用MSE和MAE对最优模型的选择整体差距是不大的。我们从损失最小的前10个参数组中选择众数作为训练参数。考虑到后面对输出层训练的过程中过拟合非常严重，在参数相差不多的情况下尽量选择小的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66e4c9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:06<00:00,  4.23s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0259764304983687\n"
     ]
    }
   ],
   "source": [
    "# 固定参数\n",
    "seq_len = 120\n",
    "patch_size = 8\n",
    "num_layer = 2\n",
    "num_head = 16\n",
    "d_model = 128\n",
    "\n",
    "masking_ratio = 0.2\n",
    "mask_expand_size = 1\n",
    "stride = 4\n",
    "\n",
    "assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX', 'AU.SHF', 'JM.DCE','RB.SHF','HC.SHF', 'I.DCE', 'M.DCE', 'CF.ZCE',]\n",
    "\n",
    "# 可变参数\n",
    "batch_size = 32\n",
    "dropout_1 = 0.18965831923308327\n",
    "dropout_2 = 0.1430970459619855\n",
    "dropout_3 = 0\n",
    "\n",
    "learning_rate = 0.001615257095302926\n",
    "weight_decay = 3.5940297438123993e-06\n",
    "gamma = 0.8462706280335419\n",
    "\n",
    "\n",
    "# 提取数据\n",
    "feature_columns = ['inday_chg_open','inday_chg_high','inday_chg_low','inday_chg_close','inday_chg_amplitude', 'ma_10','ma_26','ma_45','ma_90','ma_vol',]\n",
    "label_columns = ['label_return','down_prob','middle_prob','up_prob']\n",
    "\n",
    "feature = []\n",
    "label = []\n",
    "for asset_code in assets_list:\n",
    "    data = pd.read_csv(f'data/{asset_code}.csv')\n",
    "    data = data[data['trade_date'] < 20230901].copy() # 所有2023年以后数据不参与训练\n",
    "    feature.append(torch.tensor(data[feature_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "    label.append(torch.tensor(data[label_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "\n",
    "feature = torch.stack(feature, dim = 1)\n",
    "label = torch.stack(label, dim = 1)\n",
    "feature = feature.unfold(dimension = 0, size = seq_len, step = 1).transpose(2,3)\n",
    "label = label[seq_len-1:]\n",
    "data = RandomLoader(feature, label)\n",
    "train_loader, test_loader = data(batch_size=batch_size, slice_size=[0.7,0.29], balance=[True, True])\n",
    "\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "model = Patch_TST(input_size = 10,\n",
    "                    seq_len = seq_len,\n",
    "                    patch_size = patch_size,\n",
    "                    stride = stride,\n",
    "                    num_layer = num_layer, \n",
    "                    num_head = num_head,\n",
    "                    d_model = d_model,\n",
    "                    masking_ratio = masking_ratio,\n",
    "                    mask_expand_size = mask_expand_size,\n",
    "                    dropout_1 = dropout_1,\n",
    "                    dropout_2 = dropout_2,\n",
    "                    dropout_3 = dropout_3,\n",
    "                    ).to('cuda:0')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "\n",
    "def epoch():\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x_reconstructed, x_target = model.self_supervised(batch_x)\n",
    "        loss = loss_fn(x_reconstructed, x_target)\n",
    "        train_losses.append(loss.item()) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    test_losses = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            x_reconstructed, x_target = model.self_supervised(batch_x)\n",
    "            loss = loss_fn(x_reconstructed, x_target)\n",
    "            test_losses.append(loss.item()) \n",
    "    return np.mean(train_losses), np.mean(test_losses)\n",
    "\n",
    "def train(epochs = 30):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i in tqdm.tqdm(range(epochs)):\n",
    "        train_loss, test_loss = epoch()\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        scheduler.step()\n",
    "    plt.plot(range(epochs), train_losses)\n",
    "    plt.plot(range(epochs), test_losses)\n",
    "    plt.show()\n",
    "    return np.mean(test_losses[-10:])\n",
    "\n",
    "final_loss = train(30)\n",
    "print(final_loss)\n",
    "torch.save(model.state_dict(), 'params/self_supervised_1.params')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
