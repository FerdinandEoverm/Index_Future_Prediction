{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca6f70f3",
   "metadata": {},
   "source": [
    "在DLinear 打脸一众Transformer-based model之后，2023年普林斯顿大学IBM研究中心发表了题为<A TIME SERIES IS WORTH 64 WORDS: LONG-TERM FORECASTING WITH TRANSFORMERS>的文章\n",
    "\n",
    "提出了Patch TST 架构，其核心的Patch思想解决了传统Transformer系模型难以完全保留序列关系的特点，通过patch的方法，将部分序列关系嵌入到输入信息中。\n",
    "\n",
    "但在这一节，我先只使用其思路的前半部分，即Patch处理，暂时先不使用其Transformer架构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721f9de8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "在这个基础之上我，我们结合另一篇文章 <Technical Indicator Networks (TINs): An Interpretable Neural Architecture Modernizing Classical Technical Analysis for Adaptive Algorithmic Trading>\n",
    "\n",
    "这篇文章提出了使用神经网络优化传统技术指标的方法：\n",
    "\n",
    "假设我们将一个资产过去30天的OHLCV数据输入一个多层MLP，那么如果这个MLP参数设置得当，我们就可以得到这个资产的MACD技术指标；\n",
    "\n",
    "即，在第一层由两个节点计算快慢MA，在第二层计算DIF和DEA，在第三层得到MACD。\n",
    "\n",
    "换言之，只要我们的MLP足够大，根据通用逼近定理，我们理论上可以得到任何一个现实中存在的量价技术指标（当然，如果原始数据中不包含财务数据，那么自然不能拟合财务相关指标）；\n",
    "\n",
    "在此基础之上，如果我们允许参数可反向传播学习，那么我们就可以进一步优化这些技术指标的参数，例如MACD的MA天数，RSI的窗口等等。甚至，我们可以提炼出还没被传统交易发现的技术指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f558a635",
   "metadata": {},
   "source": [
    "因此，在这一节，我将结合这两个思想，将DLinear中的OHLCV数据先通过MLP，形成若干抽象的技术指标，然后再将这些技术指标作为特征，传入DLinear进行拟合"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
