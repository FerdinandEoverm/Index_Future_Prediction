{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894c4602",
   "metadata": {},
   "source": [
    "现在，我们可以搭建同时建模截面关系和时序关系的复合transformer架构了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f96dc34",
   "metadata": {},
   "source": [
    "我们需要重新定义encoder层，现在encoder层需要两次注意力关注，一次在时序上，关注本资产的前后序列；另一次在截面上，关注同时期的其他资产。\n",
    "\n",
    "为什么不在整个回望窗口内进行一个大的注意力机制呢？因为复杂度问题，假设资产数是 M 时间步是 N 全局注意力的开销是 O (MN)^2\n",
    "\n",
    "而时序和截面相当于是进行了两次稀疏注意力，且都是是具有比较强的可解释性的：分析一个时间点的信息，看一看前后和同时间点的其他资产，肯定比看不同时间的不同资产更重要吧？\n",
    "\n",
    "那如果确实有滞后信息需要传递呢？假设真的存在某种滞后关系，例如资产A的价格波动会在10天之后传导到B，这种机制也会被多层注意力捕获，因为我们的encoder层也是多层重叠的。第一次A的资产波动会传导到10天后的A，第二次则会从10天后的A传到到10天后的B，从而完成这种滞后效应的建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c39d94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('d:/future/Index_Future_Prediction')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import optuna\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler, Adam, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from utils import *\n",
    "from modules import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.attention import MultiHeadAttention\n",
    "from modules.addnorm import AddNorm\n",
    "from modules.ffn import PositionWiseFFN\n",
    "\n",
    "class PanelEncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Panel data transformer\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_head, num_ffn_hidden, dropout):\n",
    "        super().__init__()\n",
    "        # 纵向时间序列注意力；\n",
    "        self.time_series_attention = MultiHeadAttention(d_model, num_head)\n",
    "        # 横向截面注意力；\n",
    "        self.cross_section_attention = MultiHeadAttention(d_model, num_head)\n",
    "        # addnorm 层\n",
    "        self.addnorm = AddNorm(normalized_shape=(d_model, d_model), dropout=dropout)\n",
    "        # 通过ffn 整合信息\n",
    "        self.ffn = PositionWiseFFN(d_model, num_ffn_hidden, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        imput and output size: (batch_size, num_assets, seq_len or num_patch, d_model)\n",
    "        \"\"\"\n",
    "        # 注意力机制会自动展平前面的层，把倒数第二层作为注意力的范围。对于时序注意力，倒数第二维度应该是时间步长度\n",
    "        time_series_attention_out = self.time_series_attention(x,x,x, mask)\n",
    "        x = self.addnorm(x, time_series_attention_out)\n",
    "        # 这里交换num_assets 和 seq_len 来把资产数交换到倒数第二个维度上，让注意力关注截面\n",
    "        x = x.permute(0,2,1,3)\n",
    "        cross_section_attention = self.cross_section_attention(x,x,x, mask)\n",
    "        x = self.addnorm(x, cross_section_attention)\n",
    "        # 记得交换回来\n",
    "        x = x.permute(0,2,1,3)\n",
    "        x = self.addnorm(x, ffn_out)\n",
    "        # 最后通过ffn 整理当前时间步内部的信息\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = self.addnorm(x, ffn_out)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a91e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerPanelEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    多层PanelEncoder，由多个PanelEncoderBlock堆叠而成\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layer, d_model, num_head, num_ffn_hidden, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([PanelEncoderBlock(d_model = d_model, num_head = num_head,num_ffn_hidden = num_ffn_hidden,dropout = dropout,)for _ in range(num_layer)])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee6dd24",
   "metadata": {},
   "source": [
    "相比于预测单个资产，现在我们要预测一组资产"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46d270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioExpand(nn.Module):\n",
    "    \"\"\"\n",
    "    创建资产组合来增强数据，这些组合是原始资产的线性组合，权重被约束为 L1 范数等于 1，以模拟一个全额投资的（多空）投资组合。\n",
    "    \"\"\"\n",
    "    def __init__(self, expand_dim):\n",
    "        super().__init__()\n",
    "        self.expand_dim = expand_dim\n",
    "\n",
    "    def _portfolio_weights(self, batch_size, num_assets, device) :\n",
    "        \"\"\"生成资产组合矩阵，在最后一个维度上绝对值之和等于1\"\"\"\n",
    "        weights = 2 * torch.rand(batch_size, self.expand_dim, num_assets, device=device) - 1\n",
    "        l1_norms = torch.sum(torch.abs(weights), dim=-1, keepdim=True)\n",
    "        normalized_weights = weights / (l1_norms + 1e-16)\n",
    "        return normalized_weights\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\n",
    "        输入:\n",
    "            - x: (batch_size, num_assets, seq_len, feature_dim)\n",
    "            - y: (batch_size, num_assets, label_dim)\n",
    "        输出:\n",
    "            - expanded_x: (batch_size, num_assets + expand_dim, seq_len, feature_dim)\n",
    "            - expanded_y: (batch_size, num_assets + expand_dim, label_dim)\n",
    "        \"\"\"\n",
    "        # 验证输入维度\n",
    "        if x.dim() != 4 or y.dim() != 3:\n",
    "            raise ValueError(f\"输入维度错误! x应为4维, y应为3维, \"\n",
    "                             f\"但实际为 x: {x.dim()}维, y: {y.dim()}维\")\n",
    "        if x.shape[0] != y.shape[0] or x.shape[1] != y.shape[1]:\n",
    "            raise ValueError(\"x 和 y 的 batch_size 和 num_assets 维度必须匹配\")\n",
    "\n",
    "        batch_size, num_assets, seq_len, feature_dim = x.shape\n",
    "        device = x.device\n",
    "        weights = self._portfolio_weights(batch_size, num_assets, device)\n",
    "\n",
    "        # torch.einsum 可以在第二个维度上进行矩阵乘法（也可以用bmm）\n",
    "        expanded_x = torch.einsum('ben,bnsf->besf', weights, x)\n",
    "        expanded_y = torch.einsum('ben,bnl->bel', weights, y)\n",
    "        \n",
    "        # 拼接基资产和组合资产\n",
    "        output_x = torch.cat([x, expanded_x], dim=1)\n",
    "        output_y = torch.cat([y, expanded_y], dim=1)\n",
    "\n",
    "        return output_x, output_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa840b9b",
   "metadata": {},
   "source": [
    "为什么不选用经典transformer的加性位置编码呢？原因有两个，加性位置编码的优点是节省维度，但缺点是模型需要首先学会从汇总的信息中分离位置信息和原始信息。\n",
    "\n",
    "但是我们的时序预测维度并不高，不需要节省维度，反而我们的数据量是不足的，没必要浪费额外的成本来训练这个，因此采用concate的位置编码更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80196136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class TemporalEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Time2Vec时序编码，以concat形式扩展位置编码。\n",
    "    原始输入维度: (*, seq_len, d_model)\n",
    "    输出维度: (*, seq_len, d_model + dim_embedding)\n",
    "    \"\"\"\n",
    "    def __init__(self, dim_embedding):\n",
    "        super(TemporalEmbedding, self).__init__()\n",
    "        self.dim_embedding = dim_embedding\n",
    "        \n",
    "        # 定义 Time2Vec 的可学习参数\n",
    "        # 根据论文，第一个特征是线性的，其余的是周期性的（通过sin函数）\n",
    "        # 我们使用一个线性层来实现，这等效于创建权重(w)和偏置(b)参数\n",
    "        # 输入是1维的时间步索引，输出是 dim_embedding 维的向量\n",
    "        self.w = nn.Parameter(torch.empty(1, self.dim_embedding), requires_grad=True)\n",
    "        self.b = nn.Parameter(torch.empty(1, self.dim_embedding), requires_grad=True)\n",
    "        \n",
    "        # 初始化参数\n",
    "        nn.init.uniform_(self.w, -0.1, 0.1)\n",
    "        nn.init.uniform_(self.b, -0.1, 0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播。\n",
    "        参数:\n",
    "            x (torch.Tensor): 输入张量，形状为 (*, seq_len, d_model)\n",
    "        返回:\n",
    "            torch.Tensor: 输出张量，形状为 (*, seq_len, d_model + dim_embedding)\n",
    "        \"\"\"\n",
    "        # 保存初始形状\n",
    "        original_shape = x.shape # (*, seq_len, feature_dim)\n",
    "        seq_len = original_shape[-2]\n",
    "        batch_dims = original_shape[:-2]\n",
    "        \n",
    "        # 相对时间序号： [0, 1, 2, ..., seq_len-1]\n",
    "        tau = torch.arange(seq_len, dtype=torch.float, device=x.device).unsqueeze(-1)\n",
    "\n",
    "        # 计算时间嵌入\n",
    "        # 这是 Time2Vec 的核心计算: f(τ) = ωτ + φ\n",
    "        # tau (seq_len, 1) @ w (1, dim_embedding) -> (seq_len, dim_embedding)\n",
    "        time_embedding = tau @ self.w + self.b\n",
    "        \n",
    "        linear_part = time_embedding[:, :1] # 线性部分\n",
    "        periodic_part = torch.sin(time_embedding[:, 1:]) # 周期性部分\n",
    "\n",
    "        time_embedding = torch.cat([linear_part, periodic_part], dim=-1)\n",
    "\n",
    "        # 把编码广播到所有维度\n",
    "        target_shape = batch_dims + (seq_len, self.dim_embedding)\n",
    "        time_embedding = time_embedding.expand(target_shape)\n",
    "\n",
    "        # 拼接\n",
    "        output = torch.cat([x, time_embedding], dim=-1)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb762a1",
   "metadata": {},
   "source": [
    "Pre_train:\n",
    "x 依次通过 patch projection mask -> 分支1(masked x) -> temporal_embedding assets_embedding portfolio_expand(expand = 0) encoder reconstruction ->\n",
    "                                -> 分支2(target x) -> \n",
    "train:\n",
    "x 依次通过 patch projection  positional_encoder assets_embedding portfolio_expand(expand != 0) encoder output\n",
    "y 依次通过 portfolio_expand(expand != 0)\n",
    "\n",
    "eval:\n",
    "\n",
    "上述模块中 projection encoder reconstruction output 是可学习的，其他的不是。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153d29d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Panel_Transformer(nn.Module):\n",
    "    \"\"\"Panel Time Series Transformer\"\"\"\n",
    "    def __init__(self, input_size, seq_len, patch_size, stride, num_layer, num_head, d_model, masking_ratio, mask_expand_size, dropout_1, dropout_2, dropout_3):\n",
    "        super().__init__()\n",
    "        # 模型参数\n",
    "        self.device = 'cuda:0'\n",
    "        self.input_size = input_size\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.masking_ratio = masking_ratio\n",
    "        self.mask_expand_size = mask_expand_size\n",
    "        self.num_patch = int(np.floor((seq_len - patch_size) / stride) + 1)\n",
    "\n",
    "        # 前置层\n",
    "        self.patch = TimeSeriesPatcher(patch_size, stride)\n",
    "        self.projection = nn.Linear(input_size * patch_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model = d_model)\n",
    "\n",
    "        self.assets_embedding = nn.Embedding(num_embeddings = 53, embedding_dim = 12, _freeze = True)\n",
    "        self.assets_embedding.load_state_dict(torch.load('params/assets_embedding.params'))\n",
    "        self.portfolio_expand = PortfolioExpand(expand_dim = 10)\n",
    "        self.encoder = MultiLayerPanelEncoder(num_layer = num_layer, d_model = d_model, num_head = num_head, num_ffn_hidden = d_model * 2, dropout = dropout_2)\n",
    "\n",
    "        # 在投影之后才进行资产嵌入\n",
    "        # 一方面，可以直接传递给encoder未经处理的原始嵌入信息，避免projection还没得到学习的时候，初始的projection会错乱掉embedding关系\n",
    "        # 另一方面，每个patch只会被嵌入一次，避免一开始在daily级别就进行嵌入，导致同一个patch内有大量的冗余信息\n",
    "\n",
    "        # 预训练输出层\n",
    "        self.reconstruction = nn.Linear(d_model, input_size * patch_size)\n",
    "\n",
    "        # 输出层\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Flatten(start_dim = -2),\n",
    "            nn.Linear(self.num_patch * d_model, self.num_patch * d_model),\n",
    "            nn.Dropout(dropout_3),\n",
    "            HybridDecoder(dim_state = self.num_patch * d_model, init_prob = [0.0,0.5,0.0])\n",
    "        )\n",
    "    \n",
    "\n",
    "    def self_supervised(self, x):\n",
    "        \"\"\"\n",
    "        自监督预训练 \n",
    "        修改点:\n",
    "        - 掩蔽范围从 (batch, patch) 扩展到 (batch, asset, patch)。\n",
    "        - 在每个batch内部，对所有asset的所有patch进行随机抽样掩蔽。\n",
    "        \"\"\"\n",
    "        device = x.device\n",
    "        batch_size = x.shape[0]\n",
    "        # === 新增: 获取assets维度 ===\n",
    "        num_assets = x.shape[1] \n",
    "        \n",
    "        # === 修改 1: 改变noise和mask的形状 ===\n",
    "        # 原始形状: (batch_size, self.num_patch)\n",
    "        # 新形状: (batch_size, num_assets, self.num_patch)\n",
    "        noise = torch.rand(size=(batch_size, num_assets, self.num_patch), device=device)\n",
    "        target_mask = noise < self.masking_ratio\n",
    "        \n",
    "        # === 修改 2: 更新后备逻辑以处理新形状 ===\n",
    "        # 检查每个batch样本是否至少有一个patch被mask (跨所有assets)\n",
    "        # a.view(batch_size, -1) 将 (B, A, P) -> (B, A*P)\n",
    "        if not target_mask.view(batch_size, -1).any(dim=1).all():\n",
    "            for i in range(batch_size):\n",
    "                # 如果第i个样本中没有任何一个patch被mask\n",
    "                if not target_mask[i].any():\n",
    "                    # 随机选择一个asset和一个patch进行mask\n",
    "                    fallback_asset_idx = torch.randint(0, num_assets, (1,)).item()\n",
    "                    fallback_patch_idx = torch.randint(0, self.num_patch, (1,)).item()\n",
    "                    target_mask[i, fallback_asset_idx, fallback_patch_idx] = True\n",
    "\n",
    "        # === 修改 3: 调整形状以适应conv1d ===\n",
    "        # F.conv1d 需要一个3D输入 (N, C_in, L_in)\n",
    "        # 我们将 (B, A, P) -> (B*A, 1, P)\n",
    "        target_mask_float = target_mask.float().view(batch_size * num_assets, 1, self.num_patch)\n",
    "        \n",
    "        kernel_size = 2 * self.mask_expand_size + 1\n",
    "        kernel = torch.ones(1, 1, kernel_size, device=device)\n",
    "        padding = self.mask_expand_size\n",
    "        expanded_mask_float = F.conv1d(target_mask_float, kernel, padding=padding)\n",
    "        \n",
    "        # 将形状恢复为 (B, A, P)\n",
    "        input_mask = (expanded_mask_float > 0).squeeze(1).view(batch_size, num_assets, self.num_patch)\n",
    "        \n",
    "        x_patched = self.patch(x)  # x: (B, A, S, F) -> x_patched: (B, A, P, PF)\n",
    "        \n",
    "        # reshape_mask 现在是 (B, A, P, 1), 可以完美广播到 (B, A, P, PF)\n",
    "        reshape_mask = input_mask.unsqueeze(-1)\n",
    "        x_masked = torch.where(reshape_mask, 0.0, x_patched)\n",
    "        \n",
    "        x_projected = self.projection(x_masked)\n",
    "        x_encodered = self.encoder(x_projected) # -> (B, A, P, d_model)\n",
    "        \n",
    "        # 使用 (B, A, P) 的 target_mask 直接进行布尔索引，这会选取所有为True的元素并展平\n",
    "        x_pre_reconstruction = x_encodered[target_mask]\n",
    "        x_reconstructed = self.reconstruction(x_pre_reconstruction)\n",
    "        x_target = x_patched[target_mask]\n",
    "\n",
    "        return x_reconstructed, x_target\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播输出\"\"\"\n",
    "        x_patched = self.patch(x)\n",
    "        x_projected = self.projection(x_patched)\n",
    "        x_encodered = self.encoder(x_projected)\n",
    "        output = self.output(x_encodered)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a5de3",
   "metadata": {},
   "source": [
    "在数据处理层，有很大不同；因为我们现在一次输入的是一组资产，不能再以某一个资产的涨跌来进行训练均衡了我们直接调用原生的 dataset 和 dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5c75a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1984, 10, 120, 10])\n"
     ]
    }
   ],
   "source": [
    "# 固定参数\n",
    "seq_len = 120\n",
    "patch_size = 8\n",
    "num_layer = 2\n",
    "num_head = 16\n",
    "d_model = 128\n",
    "\n",
    "masking_ratio = 0.2\n",
    "mask_expand_size = 1\n",
    "stride = 4\n",
    "\n",
    "assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX', 'AU.SHF', 'JM.DCE','RB.SHF','HC.SHF', 'I.DCE', 'M.DCE', 'CF.ZCE',]\n",
    "\n",
    "# 可变参数\n",
    "batch_size = 32\n",
    "dropout_1 = 0.18965831923308327\n",
    "dropout_2 = 0.1430970459619855\n",
    "dropout_3 = 0\n",
    "\n",
    "learning_rate = 0.001615257095302926\n",
    "weight_decay = 3.5940297438123993e-06\n",
    "gamma = 0.8462706280335419\n",
    "\n",
    "\n",
    "# 提取数据\n",
    "feature_columns = ['inday_chg_open','inday_chg_high','inday_chg_low','inday_chg_close','inday_chg_amplitude', 'ma_10','ma_26','ma_45','ma_90','ma_vol',]\n",
    "label_columns = ['label_return','down_prob','middle_prob','up_prob']\n",
    "\n",
    "feature = []\n",
    "label = []\n",
    "for asset_code in assets_list:\n",
    "    data = pd.read_csv(f'data/{asset_code}.csv')\n",
    "    data = data[data['trade_date'] < 20230901].copy() # 所有2023年以后数据不参与训练\n",
    "    feature.append(torch.tensor(data[feature_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "    label.append(torch.tensor(data[label_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "\n",
    "feature = torch.stack(feature, dim = 1)\n",
    "label = torch.stack(label, dim = 1)\n",
    "feature = feature.unfold(dimension = 0, size = seq_len, step = 1).transpose(2,3)\n",
    "label = label[seq_len-1:]\n",
    "\n",
    "data = RandomLoader(feature, label)\n",
    "train_loader, test_loader = data(batch_size=batch_size, slice_size=[0.7,0.29], balance=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ba8182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 120, 10])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print (x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05833b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "model = Patch_TST(input_size = 10,\n",
    "                    seq_len = seq_len,\n",
    "                    patch_size = patch_size,\n",
    "                    stride = stride,\n",
    "                    num_layer = num_layer, \n",
    "                    num_head = num_head,\n",
    "                    d_model = d_model,\n",
    "                    masking_ratio = masking_ratio,\n",
    "                    mask_expand_size = mask_expand_size,\n",
    "                    dropout_1 = dropout_1,\n",
    "                    dropout_2 = dropout_2,\n",
    "                    dropout_3 = dropout_3,\n",
    "                    ).to('cuda:0')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "\n",
    "def epoch():\n",
    "    train_losses = []\n",
    "    model.train()\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        x_reconstructed, x_target = model.self_supervised(batch_x)\n",
    "        loss = loss_fn(x_reconstructed, x_target)\n",
    "        train_losses.append(loss.item()) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    test_losses = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in test_loader:\n",
    "            x_reconstructed, x_target = model.self_supervised(batch_x)\n",
    "            loss = loss_fn(x_reconstructed, x_target)\n",
    "            test_losses.append(loss.item()) \n",
    "    return np.mean(train_losses), np.mean(test_losses)\n",
    "\n",
    "def train(epochs = 30):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i in tqdm.tqdm(range(epochs)):\n",
    "        train_loss, test_loss = epoch()\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        scheduler.step()\n",
    "    plt.plot(range(epochs), train_losses)\n",
    "    plt.plot(range(epochs), test_losses)\n",
    "    plt.show()\n",
    "    return np.mean(test_losses[-10:])\n",
    "\n",
    "final_loss = train(30)\n",
    "print(final_loss)\n",
    "torch.save(model.state_dict(), 'params/self_supervised_1.params')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
