{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('d:/future/Index_Future_Prediction')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler, Adam, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import optuna\n",
    "from utils import *\n",
    "from modules.truncate import SequenceTruncate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ee6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline_LSTM(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_1, dropout_2, dropout_3):\n",
    "        super(Baseline_LSTM, self).__init__()\n",
    "        self.device = 'cuda:0'\n",
    "        self.hidden_size = hidden_size\n",
    "        self.truncate = SequenceTruncate(dropout_1)\n",
    "        self.process = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            dropout = dropout_2,\n",
    "            batch_first = True,\n",
    "            # nonlinearity='relu',\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Dropout(dropout_3),\n",
    "            HybridDecoder(dim_state = hidden_size, init_prob = [0.0,0.5,0.0])\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #为了提升模型的泛化能力，我们每次输入都随机舍弃一部分前端的序列\n",
    "        front_shape = x.shape[:-2]\n",
    "        x = self.truncate(x)\n",
    "        x = torch.flatten(x, 0, -3)\n",
    "        x = self.process(x)[0][:,-1,:]\n",
    "        x = x.reshape(*front_shape, self.hidden_size)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    batch_size = 64\n",
    "    seq_len = 40\n",
    "    hidden_size = 5\n",
    "    num_layers = 2\n",
    "\n",
    "    dropout_1 = trial.suggest_float(\"dropout_1\", 0.0, 0.5)\n",
    "    dropout_2 = trial.suggest_float(\"dropout_2\", 0.0, 0.5)\n",
    "    dropout_3 = trial.suggest_float(\"dropout_3\", 0.0, 0.5)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.01, 0.05)\n",
    "    weight_decay = 3e-4\n",
    "    learning_rate = 1e-3\n",
    "    \n",
    "\n",
    "    # 提取数据\n",
    "    feature_columns = ['inday_chg_open','inday_chg_high','inday_chg_low','inday_chg_close','inday_chg_amplitude', 'ma_10','ma_26','ma_45','ma_90','ma_vol',]\n",
    "    label_columns = ['label_return','down_prob','middle_prob','up_prob']\n",
    "    assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX', 'AU.SHF', 'JM.DCE','RB.SHF','HC.SHF', 'I.DCE', 'M.DCE', 'CF.ZCE',]\n",
    "    assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX',]\n",
    "    feature = []\n",
    "    label = []\n",
    "\n",
    "    for asset_code in assets_list:\n",
    "        data = pd.read_csv(f'data/{asset_code}.csv')\n",
    "        feature.append(torch.tensor(data[feature_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "        label.append(torch.tensor(data[label_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "\n",
    "    # 加载数据\n",
    "    feature = torch.stack(feature, dim = 1)\n",
    "    label = torch.stack(label, dim = 1)\n",
    "    print(feature.shape, label.shape)\n",
    "\n",
    "    # 折叠时间步\n",
    "    feature = feature.unfold(dimension = 0, size = seq_len, step = 1).transpose(2,3)\n",
    "    label = label[seq_len-1:]\n",
    "    print(feature.shape, label.shape)\n",
    "\n",
    "    data = RandomLoader(feature, label)\n",
    "    recorder = PredictionRecorder()\n",
    "    animator = TrainMonitor(figsize=(12,6))\n",
    "\n",
    "    result = np.zeros(shape = (10, len(assets_list), 4))\n",
    "    precision_list = []\n",
    "\n",
    "    result = []\n",
    "    for i in range(10):\n",
    "        j = 0\n",
    "        train_loader, test_loader = data(batch_size=batch_size, slice_size=[0.6, 0.1], balance=[True, False])\n",
    "        \n",
    "        animator.reset()\n",
    "        loss_fn = HybridLoss(alpha = alpha, delta = 1.3, show_loss = False) #控制损失在1：3左右\n",
    "        model = Baseline_LSTM(input_size = 10,\n",
    "                              hidden_size = hidden_size,\n",
    "                              num_layers = num_layers,\n",
    "                              dropout_1 = dropout_1,\n",
    "                              dropout_2 = dropout_2,\n",
    "                              dropout_3 = dropout_3,\n",
    "                              ).to('cuda:0')\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "        train = ModelTrain(model = model,\n",
    "                    train_loader = train_loader,\n",
    "                    test_loader = test_loader,\n",
    "                    loss_fn = loss_fn,\n",
    "                    optimizer = optimizer,\n",
    "                    scheduler = scheduler,\n",
    "                    recorder = recorder,\n",
    "                    graph = animator,\n",
    "                    )\n",
    "        prediction, precision = train.epoch_train(epochs = 10, early_stop = 100)\n",
    "\n",
    "        precision_list.append(precision)\n",
    "\n",
    "\n",
    "    return np.mean(precision_list)/np.std(precision_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06684a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 运行优化 ---\n",
    "if __name__ == \"__main__\":\n",
    "    # 我们要最大化准确率\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=30)  # 运行30次试验\n",
    "\n",
    "    print(\"优化完成!\")\n",
    "    print(\"最佳试验的编号: \", study.best_trial.number)\n",
    "    print(\"最佳准确率: \", study.best_value)\n",
    "    print(\"最佳超参数: \", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_assets = pd.DataFrame({\n",
    "#     'stage_1_prediction': np.mean(result, axis = 0)[:,0],\n",
    "#     'stage_2_prediction': np.mean(result, axis = 0)[:,2],\n",
    "\n",
    "#     'stage_1_precision': np.mean(result, axis = 0)[:,1],\n",
    "#     'stage_2_precision': np.mean(result, axis = 0)[:,3],\n",
    "\n",
    "#     'stage_1_precision_std': np.std(result, axis = 0)[:,1],\n",
    "#     'stage_2_precision_std': np.std(result, axis = 0)[:,3],\n",
    "# })\n",
    "# all_assets.index = pd.Series(assets_list)\n",
    "# for col in all_assets.columns:\n",
    "#     all_assets[col] = all_assets[col].apply(lambda x: f\"{x:.1%}\")\n",
    "\n",
    "# # 转换为Markdown\n",
    "# markdown_table = all_assets.to_markdown(index=False)\n",
    "# print(f'hidden_size: {hidden_size}, num_layers: {num_layers}, seq_len: {seq_len}')\n",
    "# print(markdown_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99726067",
   "metadata": {},
   "source": [
    "优化完成!\n",
    "最佳试验的编号:  15\n",
    "最佳准确率:  1.7570846318543656\n",
    "最佳超参数:  {'learning_rate': 0.0017696481376409101, 'weight_decay': 0.00036082540684983, 'dropout': 0.3203330257231537, 'batch_size': 64, 'seq_len': 40, 'hidden_size': 10, 'num_layers': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c978788",
   "metadata": {},
   "source": [
    "\n",
    "最佳试验的编号:  3\n",
    "最佳准确率:  1.2913507249916159\n",
    "最佳超参数:  {'learning_rate': 0.0012439264519395815, 'weight_decay': 2.2229309086256647e-05, 'dropout': 0.3640695831669655, 'batch_size': 64, 'seq_len': 30, 'hidden_size': 5, 'num_layers': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336eb8dd",
   "metadata": {},
   "source": [
    "最佳试验的编号:  7\n",
    "最佳准确率:  1.0722981008506158\n",
    "最佳超参数:  {'weight_decay': 4.048437595935014e-06, 'seq_len': 38, 'hidden_size': 5, 'num_layers': 2}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
