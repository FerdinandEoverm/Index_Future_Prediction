{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d70f4bb",
   "metadata": {},
   "source": [
    "这里 我们使用普通RNN和SegRNN架构对比patch的作用\n",
    "\n",
    "为什么要进行Patch？\n",
    "\n",
    "我们希望收集一个长序列的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f711495",
   "metadata": {},
   "source": [
    "我们可以将RNN类的模型理解为一个顺序的信息收集器，这个收集器可以从前向后逐步遍历所有的时间步，\n",
    "\n",
    "在每个时间步上，得到的信息储存是之前的历史信息+本次收集的信息，在最后用收集的信息进行输出\n",
    "\n",
    "因为提升预测的需要，我们必须扩展序列长度，来获取更全面的信息；\n",
    "\n",
    "但是如果总的距离过长，就必须压缩历史信息的占比，导致远距离信息微弱甚至丢失\n",
    "\n",
    "而如果不压缩历史信息，会导致梯度爆炸。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899375c0",
   "metadata": {},
   "source": [
    "因此我们可以参考CNN的思路，采用1维卷积的方式尝试解决这个问题：\n",
    "\n",
    "首先，我们将原始序列分为长度为某个值子序列，然后每若干步采样一次。\n",
    "\n",
    "在每个子序列内，可以使用Linear或RNN，尝试在序列中识别出小段的上涨趋势、下跌趋势和平盘之类的信息，并抽象为信息向量；\n",
    "\n",
    "由于每个子序列内长度有限，RNN可以充分吸取信息而不必担心长序列信息丢失的问题。\n",
    "\n",
    "如果此时的序列仍然过长，我们可以再加入一层，将上一层得到的子序列再分组为新的子序列，同样用Linear或RNN收集子序列信息。\n",
    "\n",
    "在这一层我们可以识别出更复杂的形态组合，例如连续多端上涨之后的下跌，抑或是平盘之后的变盘形态等等。\n",
    "\n",
    "直到整个序列的长度已经很小了，此时我们再使用RNN进行最后一次收集，并将的得到的信息向量传入输出层输出出我们需要的任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90b5989",
   "metadata": {},
   "source": [
    "这样一来，每层的RNN都面对一个相对较小的子序列，不至于出现长距离信息丢失的问题\n",
    "\n",
    "而不同层的RNN处理的问题是不一样的，其参数和方式也有所不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f92810",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('d:/future/Index_Future_Prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1525e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler, Adam, AdamW\n",
    "from scipy.stats import norm, t\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c794ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.random_split import RandomSplit, CallableDataset\n",
    "from utils.back_test import BackTest\n",
    "from utils.hybrid_loss import HybridLoss\n",
    "from utils.hybrid_decoder import HybridDecoder\n",
    "from utils.prediction_recorder import PredictionRecorder\n",
    "from utils.train_animator import TrainAnimator\n",
    "from utils.model_train import ModelTrain\n",
    "from utils.get_ohlcv import GetOHLCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94dd7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX', 'AU.SHF', 'FU.SHF', 'JM.DCE','RB.SHF','HC.SHF', 'I.DCE', 'M.DCE', 'CF.ZCE',]\n",
    "assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b29a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 20\n",
    "pred_len = 5\n",
    "train_ratio = 0.5\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.02\n",
    "threshold_ratio = 0.25\n",
    "\n",
    "patch_size = 5\n",
    "\n",
    "hidden_size = 10\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10b8aeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_split(train_ratio, validation_ratio, test_ratio):\n",
    "    source = GetOHLCV()\n",
    "    sample_date = source.get_data('M.DCE', 5, 0.3)\n",
    "    date_column = sample_date['trade_date'].copy()\n",
    "    total_size = len(date_column)\n",
    "    train_size = int(train_ratio * total_size)\n",
    "    validation_size = int(validation_ratio * total_size)\n",
    "    test_size = int(test_ratio * total_size)\n",
    "    random_split = np.random.randint(train_size, total_size - validation_size - test_size)\n",
    "    validation_start = date_column.iloc[random_split]\n",
    "    test_start = date_column.iloc[random_split+validation_size]\n",
    "    test_end = date_column.iloc[random_split+validation_size+test_size]\n",
    "    return validation_start, test_start, test_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a3ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_set(assets_list, validation_start, test_start, test_end, seq_len, pred_len, threshold_ratio):\n",
    "\n",
    "    source = GetOHLCV()\n",
    "\n",
    "    train_set = None\n",
    "    validation_set = None\n",
    "    test_set = None\n",
    "    feature_column = ['open', 'high', 'low', 'close', 'log_open','log_high','log_low','log_close','log_amount',]\n",
    "    label_column = ['label_return','down_prob','middle_prob','up_prob']\n",
    "    \n",
    "    for code in assets_list:\n",
    "\n",
    "        data = source.get_data(code, pred_len, threshold_ratio)\n",
    "\n",
    "        train_data = data[data['trade_date'] < validation_start].copy()\n",
    "        validation_data = data[(data['trade_date'] >= validation_start) & (data['trade_date'] < test_start)].copy()\n",
    "        test_data = data[(data['trade_date'] >= test_start) & (data['trade_date'] < test_end)].copy()\n",
    "    \n",
    "        train_feature = torch.tensor(train_data[feature_column].values, dtype = torch.float32, device = 'cuda:0')\n",
    "        train_feature = train_feature.unfold(dimension = 0, size = seq_len, step = 1).transpose(1,2)\n",
    "\n",
    "        validation_feature = torch.tensor(validation_data[feature_column].values, dtype = torch.float32, device = 'cuda:0')\n",
    "        validation_feature = validation_feature.unfold(dimension = 0, size = seq_len, step = 1).transpose(1,2)\n",
    "\n",
    "        test_feature = torch.tensor(test_data[feature_column].values, dtype = torch.float32, device = 'cuda:0')\n",
    "        test_feature = test_feature.unfold(dimension = 0, size = seq_len, step = 1).transpose(1,2)\n",
    "\n",
    "\n",
    "\n",
    "        train_label = torch.tensor(train_data[label_column].values, dtype = torch.float32, device = 'cuda:0')\n",
    "        train_label = train_label[seq_len-1:]\n",
    "\n",
    "        validation_label = torch.tensor(validation_data[label_column].values, dtype = torch.float32, device = 'cuda:0')\n",
    "        validation_label = validation_label[seq_len-1:]\n",
    "\n",
    "        test_label = torch.tensor(test_data[label_column].values, dtype = torch.float32, device = 'cuda:0')\n",
    "        test_label = test_label[seq_len-1:]\n",
    "\n",
    "\n",
    "\n",
    "        if train_set == None:\n",
    "            train_set = CallableDataset(train_feature, train_label)\n",
    "        else:\n",
    "            train_set = train_set + CallableDataset(train_feature, train_label)\n",
    "\n",
    "        if validation_set == None:\n",
    "            validation_set = CallableDataset(validation_feature, validation_label)\n",
    "        else:\n",
    "            validation_set = validation_set + CallableDataset(validation_feature, validation_label)\n",
    "        \n",
    "        if test_set == None:\n",
    "            test_set = CallableDataset(test_feature, test_label)\n",
    "        else:\n",
    "            test_set = test_set + CallableDataset(test_feature, test_label)\n",
    "\n",
    "    return train_set, validation_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66fa0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_start, test_start, test_end = get_random_split(train_ratio, validation_ratio, test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c494516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animator data has been reset.\n"
     ]
    }
   ],
   "source": [
    "recorder = PredictionRecorder()\n",
    "animator = TrainAnimator(figsize=(12,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045c06dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.6046e+00, -1.7517e+00, -1.2528e+00, -8.9882e-01, -6.2426e-01,\n",
       "          -3.9992e-01, -2.1025e-01, -4.5944e-02,  9.8982e-02,  2.2862e-01,\n",
       "           3.4590e-01,  4.5296e-01,  5.5145e-01,  6.4263e-01,  7.2753e-01,\n",
       "           8.0694e-01,  8.8153e-01,  9.5186e-01,  1.0184e+00,  1.0815e+00],\n",
       "         [ 1.1415e+00,  1.1988e+00,  1.2535e+00,  1.3058e+00,  1.3561e+00,\n",
       "           1.4043e+00,  1.4508e+00,  1.4955e+00,  1.5387e+00,  1.5804e+00,\n",
       "           1.6208e+00,  1.6598e+00,  1.6977e+00,  1.7344e+00,  1.7701e+00,\n",
       "           1.8047e+00,  1.8385e+00,  1.8713e+00,  1.9032e+00,  1.9344e+00],\n",
       "         [ 1.9648e+00,  1.9944e+00,  2.0234e+00,  2.0517e+00,  2.0793e+00,\n",
       "           2.1064e+00,  2.1328e+00,  2.1587e+00,  2.1841e+00,  2.2090e+00,\n",
       "           2.2333e+00,  2.2572e+00,  2.2806e+00,  2.3036e+00,  2.3262e+00,\n",
       "           2.3484e+00,  2.3702e+00,  2.3916e+00,  2.4126e+00,  2.4333e+00],\n",
       "         [ 2.4536e+00,  2.4736e+00,  2.4933e+00,  2.5127e+00,  2.5318e+00,\n",
       "           2.5506e+00,  2.5691e+00,  2.5873e+00,  2.6053e+00,  2.6230e+00,\n",
       "           2.6404e+00,  2.6576e+00,  2.6746e+00,  2.6913e+00,  2.7079e+00,\n",
       "           2.7242e+00,  2.7402e+00,  2.7561e+00,  2.7718e+00,  2.7873e+00],\n",
       "         [ 2.8026e+00,  2.8176e+00,  2.8326e+00,  2.8473e+00,  2.8619e+00,\n",
       "           2.8763e+00,  2.8905e+00,  2.9045e+00,  2.9184e+00,  2.9322e+00,\n",
       "           2.9458e+00,  2.9592e+00,  2.9725e+00,  2.9857e+00,  2.9987e+00,\n",
       "           3.0116e+00,  3.0244e+00,  3.0370e+00,  3.0495e+00,  3.0618e+00],\n",
       "         [ 3.0741e+00,  3.0862e+00,  3.0982e+00,  3.1101e+00,  3.1219e+00,\n",
       "           3.1335e+00,  3.1451e+00,  3.1565e+00,  3.1679e+00,  3.1791e+00,\n",
       "           3.1902e+00,  3.2013e+00,  3.2122e+00,  3.2231e+00,  3.2338e+00,\n",
       "           3.2445e+00,  3.2550e+00,  3.2655e+00,  3.2759e+00,  3.2862e+00],\n",
       "         [ 3.2964e+00,  3.3065e+00,  3.3166e+00,  3.3265e+00,  3.3364e+00,\n",
       "           3.3462e+00,  3.3559e+00,  3.3656e+00,  3.3752e+00,  3.3847e+00,\n",
       "           3.3941e+00,  3.4034e+00,  3.4127e+00,  3.4219e+00,  3.4311e+00,\n",
       "           3.4402e+00,  3.4492e+00,  3.4581e+00,  3.4670e+00,  3.4758e+00]],\n",
       "\n",
       "        [[-1.7076e+01, -1.3594e+01, -1.1557e+01, -1.0112e+01, -8.9911e+00,\n",
       "          -8.0752e+00, -7.3008e+00, -6.6300e+00, -6.0384e+00, -5.5091e+00,\n",
       "          -5.0303e+00, -4.5932e+00, -4.1911e+00, -3.8188e+00, -3.4722e+00,\n",
       "          -3.1480e+00, -2.8435e+00, -2.5564e+00, -2.2847e+00, -2.0271e+00],\n",
       "         [-1.7820e+00, -1.5483e+00, -1.3250e+00, -1.1112e+00, -9.0611e-01,\n",
       "          -7.0909e-01, -5.1950e-01, -3.3681e-01, -1.6053e-01,  9.7756e-03,\n",
       "           1.7449e-01,  3.3398e-01,  4.8857e-01,  6.3853e-01,  7.8415e-01,\n",
       "           9.2567e-01,  1.0633e+00,  1.1973e+00,  1.3278e+00,  1.4549e+00],\n",
       "         [ 1.5790e+00,  1.7000e+00,  1.8182e+00,  1.9337e+00,  2.0466e+00,\n",
       "           2.1570e+00,  2.2651e+00,  2.3708e+00,  2.4744e+00,  2.5759e+00,\n",
       "           2.6754e+00,  2.7729e+00,  2.8686e+00,  2.9625e+00,  3.0547e+00,\n",
       "           3.1452e+00,  3.2341e+00,  3.3215e+00,  3.4074e+00,  3.4918e+00],\n",
       "         [ 3.5748e+00,  3.6565e+00,  3.7369e+00,  3.8160e+00,  3.8939e+00,\n",
       "           3.9706e+00,  4.0461e+00,  4.1205e+00,  4.1939e+00,  4.2662e+00,\n",
       "           4.3374e+00,  4.4077e+00,  4.4770e+00,  4.5453e+00,  4.6128e+00,\n",
       "           4.6793e+00,  4.7450e+00,  4.8098e+00,  4.8738e+00,  4.9370e+00],\n",
       "         [ 4.9994e+00,  5.0610e+00,  5.1219e+00,  5.1821e+00,  5.2415e+00,\n",
       "           5.3003e+00,  5.3583e+00,  5.4157e+00,  5.4725e+00,  5.5286e+00,\n",
       "           5.5841e+00,  5.6391e+00,  5.6934e+00,  5.7471e+00,  5.8002e+00,\n",
       "           5.8528e+00,  5.9049e+00,  5.9564e+00,  6.0074e+00,  6.0579e+00],\n",
       "         [ 6.1079e+00,  6.1574e+00,  6.2064e+00,  6.2549e+00,  6.3030e+00,\n",
       "           6.3506e+00,  6.3978e+00,  6.4445e+00,  6.4908e+00,  6.5367e+00,\n",
       "           6.5822e+00,  6.6272e+00,  6.6719e+00,  6.7161e+00,  6.7600e+00,\n",
       "           6.8035e+00,  6.8466e+00,  6.8894e+00,  6.9318e+00,  6.9738e+00],\n",
       "         [ 7.0155e+00,  7.0568e+00,  7.0979e+00,  7.1385e+00,  7.1789e+00,\n",
       "           7.2189e+00,  7.2586e+00,  7.2980e+00,  7.3371e+00,  7.3759e+00,\n",
       "           7.4144e+00,  7.4526e+00,  7.4905e+00,  7.5281e+00,  7.5655e+00,\n",
       "           7.6026e+00,  7.6394e+00,  7.6759e+00,  7.7122e+00,  7.7482e+00]],\n",
       "\n",
       "        [[-3.3115e+01, -2.7253e+01, -2.3823e+01, -2.1390e+01, -1.9503e+01,\n",
       "          -1.7961e+01, -1.6657e+01, -1.5528e+01, -1.4532e+01, -1.3641e+01,\n",
       "          -1.2834e+01, -1.2099e+01, -1.1422e+01, -1.0795e+01, -1.0211e+01,\n",
       "          -9.6654e+00, -9.1526e+00, -8.6692e+00, -8.2119e+00, -7.7781e+00],\n",
       "         [-7.3654e+00, -6.9720e+00, -6.5960e+00, -6.2361e+00, -5.8908e+00,\n",
       "          -5.5591e+00, -5.2399e+00, -4.9323e+00, -4.6355e+00, -4.3488e+00,\n",
       "          -4.0715e+00, -3.8029e+00, -3.5427e+00, -3.2902e+00, -3.0450e+00,\n",
       "          -2.8068e+00, -2.5750e+00, -2.3495e+00, -2.1298e+00, -1.9157e+00],\n",
       "         [-1.7068e+00, -1.5030e+00, -1.3040e+00, -1.1095e+00, -9.1948e-01,\n",
       "          -7.3359e-01, -5.5169e-01, -3.7363e-01, -1.9924e-01, -2.8368e-02,\n",
       "           1.3912e-01,  3.0335e-01,  4.6445e-01,  6.2255e-01,  7.7774e-01,\n",
       "           9.3013e-01,  1.0798e+00,  1.2269e+00,  1.3715e+00,  1.5137e+00],\n",
       "         [ 1.6535e+00,  1.7910e+00,  1.9263e+00,  2.0595e+00,  2.1906e+00,\n",
       "           2.3198e+00,  2.4470e+00,  2.5723e+00,  2.6957e+00,  2.8174e+00,\n",
       "           2.9374e+00,  3.0557e+00,  3.1723e+00,  3.2874e+00,  3.4009e+00,\n",
       "           3.5130e+00,  3.6235e+00,  3.7327e+00,  3.8404e+00,  3.9468e+00],\n",
       "         [ 4.0519e+00,  4.1556e+00,  4.2582e+00,  4.3594e+00,  4.4595e+00,\n",
       "           4.5585e+00,  4.6562e+00,  4.7529e+00,  4.8485e+00,  4.9430e+00,\n",
       "           5.0364e+00,  5.1289e+00,  5.2203e+00,  5.3108e+00,  5.4003e+00,\n",
       "           5.4888e+00,  5.5765e+00,  5.6632e+00,  5.7491e+00,  5.8341e+00],\n",
       "         [ 5.9182e+00,  6.0016e+00,  6.0841e+00,  6.1658e+00,  6.2467e+00,\n",
       "           6.3269e+00,  6.4063e+00,  6.4850e+00,  6.5629e+00,  6.6402e+00,\n",
       "           6.7167e+00,  6.7926e+00,  6.8678e+00,  6.9423e+00,  7.0161e+00,\n",
       "           7.0894e+00,  7.1620e+00,  7.2340e+00,  7.3053e+00,  7.3761e+00],\n",
       "         [ 7.4463e+00,  7.5159e+00,  7.5849e+00,  7.6534e+00,  7.7214e+00,\n",
       "           7.7888e+00,  7.8556e+00,  7.9220e+00,  7.9878e+00,  8.0531e+00,\n",
       "           8.1179e+00,  8.1822e+00,  8.2460e+00,  8.3094e+00,  8.3723e+00,\n",
       "           8.4347e+00,  8.4967e+00,  8.5582e+00,  8.6192e+00,  8.6799e+00]],\n",
       "\n",
       "        [[-5.0435e+01, -4.2214e+01, -3.7405e+01, -3.3993e+01, -3.1346e+01,\n",
       "          -2.9183e+01, -2.7355e+01, -2.5771e+01, -2.4374e+01, -2.3125e+01,\n",
       "          -2.1994e+01, -2.0962e+01, -2.0013e+01, -1.9134e+01, -1.8315e+01,\n",
       "          -1.7550e+01, -1.6831e+01, -1.6153e+01, -1.5512e+01, -1.4903e+01],\n",
       "         [-1.4325e+01, -1.3773e+01, -1.3246e+01, -1.2741e+01, -1.2257e+01,\n",
       "          -1.1791e+01, -1.1344e+01, -1.0912e+01, -1.0496e+01, -1.0094e+01,\n",
       "          -9.7052e+00, -9.3287e+00, -8.9637e+00, -8.6096e+00, -8.2658e+00,\n",
       "          -7.9317e+00, -7.6067e+00, -7.2904e+00, -6.9823e+00, -6.6820e+00],\n",
       "         [-6.3891e+00, -6.1033e+00, -5.8242e+00, -5.5515e+00, -5.2850e+00,\n",
       "          -5.0243e+00, -4.7692e+00, -4.5195e+00, -4.2750e+00, -4.0353e+00,\n",
       "          -3.8005e+00, -3.5702e+00, -3.3442e+00, -3.1225e+00, -2.9049e+00,\n",
       "          -2.6912e+00, -2.4812e+00, -2.2750e+00, -2.0722e+00, -1.8729e+00],\n",
       "         [-1.6768e+00, -1.4839e+00, -1.2942e+00, -1.1074e+00, -9.2348e-01,\n",
       "          -7.4240e-01, -5.6404e-01, -3.8832e-01, -2.1516e-01, -4.4505e-02,\n",
       "           1.2374e-01,  2.8963e-01,  4.5323e-01,  6.1460e-01,  7.7381e-01,\n",
       "           9.3091e-01,  1.0860e+00,  1.2390e+00,  1.3901e+00,  1.5393e+00],\n",
       "         [ 1.6866e+00,  1.8322e+00,  1.9759e+00,  2.1180e+00,  2.2583e+00,\n",
       "           2.3971e+00,  2.5342e+00,  2.6697e+00,  2.8038e+00,  2.9363e+00,\n",
       "           3.0674e+00,  3.1970e+00,  3.3252e+00,  3.4521e+00,  3.5776e+00,\n",
       "           3.7018e+00,  3.8247e+00,  3.9463e+00,  4.0668e+00,  4.1860e+00],\n",
       "         [ 4.3040e+00,  4.4208e+00,  4.5365e+00,  4.6511e+00,  4.7646e+00,\n",
       "           4.8771e+00,  4.9884e+00,  5.0988e+00,  5.2081e+00,  5.3164e+00,\n",
       "           5.4238e+00,  5.5301e+00,  5.6356e+00,  5.7401e+00,  5.8436e+00,\n",
       "           5.9463e+00,  6.0481e+00,  6.1491e+00,  6.2492e+00,  6.3484e+00],\n",
       "         [ 6.4469e+00,  6.5445e+00,  6.6413e+00,  6.7374e+00,  6.8326e+00,\n",
       "           6.9271e+00,  7.0209e+00,  7.1139e+00,  7.2062e+00,  7.2978e+00,\n",
       "           7.3887e+00,  7.4789e+00,  7.5684e+00,  7.6573e+00,  7.7454e+00,\n",
       "           7.8330e+00,  7.9199e+00,  8.0061e+00,  8.0918e+00,  8.1768e+00]],\n",
       "\n",
       "        [[-6.8693e+01, -5.8120e+01, -5.1935e+01, -4.7547e+01, -4.4143e+01,\n",
       "          -4.1362e+01, -3.9010e+01, -3.6973e+01, -3.5177e+01, -3.3570e+01,\n",
       "          -3.2116e+01, -3.0788e+01, -2.9568e+01, -2.8437e+01, -2.7385e+01,\n",
       "          -2.6400e+01, -2.5475e+01, -2.4604e+01, -2.3779e+01, -2.2996e+01],\n",
       "         [-2.2252e+01, -2.1543e+01, -2.0864e+01, -2.0215e+01, -1.9593e+01,\n",
       "          -1.8994e+01, -1.8419e+01, -1.7864e+01, -1.7329e+01, -1.6811e+01,\n",
       "          -1.6311e+01, -1.5827e+01, -1.5358e+01, -1.4902e+01, -1.4460e+01,\n",
       "          -1.4030e+01, -1.3612e+01, -1.3206e+01, -1.2809e+01, -1.2423e+01],\n",
       "         [-1.2047e+01, -1.1679e+01, -1.1320e+01, -1.0969e+01, -1.0627e+01,\n",
       "          -1.0291e+01, -9.9633e+00, -9.6421e+00, -9.3276e+00, -9.0194e+00,\n",
       "          -8.7174e+00, -8.4212e+00, -8.1306e+00, -7.8455e+00, -7.5656e+00,\n",
       "          -7.2907e+00, -7.0208e+00, -6.7555e+00, -6.4947e+00, -6.2383e+00],\n",
       "         [-5.9862e+00, -5.7382e+00, -5.4941e+00, -5.2539e+00, -5.0174e+00,\n",
       "          -4.7845e+00, -4.5551e+00, -4.3291e+00, -4.1064e+00, -3.8869e+00,\n",
       "          -3.6706e+00, -3.4572e+00, -3.2468e+00, -3.0393e+00, -2.8345e+00,\n",
       "          -2.6325e+00, -2.4331e+00, -2.2363e+00, -2.0419e+00, -1.8501e+00],\n",
       "         [-1.6606e+00, -1.4734e+00, -1.2885e+00, -1.1058e+00, -9.2531e-01,\n",
       "          -7.4690e-01, -5.7056e-01, -3.9622e-01, -2.2386e-01, -5.3425e-02,\n",
       "           1.1513e-01,  2.8184e-01,  4.4674e-01,  6.0989e-01,  7.7131e-01,\n",
       "           9.3104e-01,  1.0891e+00,  1.2456e+00,  1.4004e+00,  1.5537e+00],\n",
       "         [ 1.7055e+00,  1.8558e+00,  2.0046e+00,  2.1520e+00,  2.2980e+00,\n",
       "           2.4426e+00,  2.5858e+00,  2.7277e+00,  2.8683e+00,  3.0076e+00,\n",
       "           3.1456e+00,  3.2824e+00,  3.4180e+00,  3.5524e+00,  3.6856e+00,\n",
       "           3.8177e+00,  3.9486e+00,  4.0785e+00,  4.2072e+00,  4.3348e+00],\n",
       "         [ 4.4614e+00,  4.5870e+00,  4.7115e+00,  4.8350e+00,  4.9575e+00,\n",
       "           5.0791e+00,  5.1997e+00,  5.3193e+00,  5.4380e+00,  5.5558e+00,\n",
       "           5.6727e+00,  5.7887e+00,  5.9038e+00,  6.0181e+00,  6.1315e+00,\n",
       "           6.2441e+00,  6.3558e+00,  6.4667e+00,  6.5769e+00,  6.6862e+00]],\n",
       "\n",
       "        [[-8.7687e+01, -7.4765e+01, -6.7206e+01, -6.1843e+01, -5.7683e+01,\n",
       "          -5.4285e+01, -5.1411e+01, -4.8921e+01, -4.6726e+01, -4.4762e+01,\n",
       "          -4.2985e+01, -4.1363e+01, -3.9870e+01, -3.8489e+01, -3.7203e+01,\n",
       "          -3.6000e+01, -3.4869e+01, -3.3804e+01, -3.2796e+01, -3.1840e+01],\n",
       "         [-3.0930e+01, -3.0063e+01, -2.9234e+01, -2.8441e+01, -2.7680e+01,\n",
       "          -2.6949e+01, -2.6245e+01, -2.5567e+01, -2.4913e+01, -2.4281e+01,\n",
       "          -2.3670e+01, -2.3078e+01, -2.2504e+01, -2.1947e+01, -2.1407e+01,\n",
       "          -2.0882e+01, -2.0371e+01, -1.9874e+01, -1.9390e+01, -1.8918e+01],\n",
       "         [-1.8457e+01, -1.8008e+01, -1.7570e+01, -1.7141e+01, -1.6722e+01,\n",
       "          -1.6312e+01, -1.5911e+01, -1.5519e+01, -1.5134e+01, -1.4758e+01,\n",
       "          -1.4389e+01, -1.4027e+01, -1.3672e+01, -1.3323e+01, -1.2981e+01,\n",
       "          -1.2645e+01, -1.2315e+01, -1.1991e+01, -1.1672e+01, -1.1359e+01],\n",
       "         [-1.1051e+01, -1.0748e+01, -1.0449e+01, -1.0156e+01, -9.8667e+00,\n",
       "          -9.5821e+00, -9.3018e+00, -9.0256e+00, -8.7534e+00, -8.4852e+00,\n",
       "          -8.2207e+00, -7.9600e+00, -7.7029e+00, -7.4492e+00, -7.1990e+00,\n",
       "          -6.9521e+00, -6.7084e+00, -6.4678e+00, -6.2303e+00, -5.9958e+00],\n",
       "         [-5.7642e+00, -5.5355e+00, -5.3095e+00, -5.0863e+00, -4.8656e+00,\n",
       "          -4.6476e+00, -4.4321e+00, -4.2190e+00, -4.0084e+00, -3.8001e+00,\n",
       "          -3.5941e+00, -3.3903e+00, -3.1888e+00, -2.9894e+00, -2.7921e+00,\n",
       "          -2.5969e+00, -2.4037e+00, -2.2125e+00, -2.0233e+00, -1.8359e+00],\n",
       "         [-1.6504e+00, -1.4667e+00, -1.2849e+00, -1.1047e+00, -9.2634e-01,\n",
       "          -7.4963e-01, -5.7459e-01, -4.0117e-01, -2.2935e-01, -5.9097e-02,\n",
       "           1.0961e-01,  2.7681e-01,  4.4252e-01,  6.0677e-01,  7.6959e-01,\n",
       "           9.3099e-01,  1.0910e+00,  1.2497e+00,  1.4070e+00,  1.5630e+00],\n",
       "         [ 1.7177e+00,  1.8711e+00,  2.0233e+00,  2.1743e+00,  2.3240e+00,\n",
       "           2.4726e+00,  2.6199e+00,  2.7662e+00,  2.9112e+00,  3.0552e+00,\n",
       "           3.1980e+00,  3.3398e+00,  3.4805e+00,  3.6202e+00,  3.7588e+00,\n",
       "           3.8963e+00,  4.0329e+00,  4.1685e+00,  4.3031e+00,  4.4367e+00]],\n",
       "\n",
       "        [[-1.0729e+02, -9.2018e+01, -8.3087e+01, -7.6749e+01, -7.1834e+01,\n",
       "          -6.7818e+01, -6.4422e+01, -6.1480e+01, -5.8886e+01, -5.6565e+01,\n",
       "          -5.4465e+01, -5.2549e+01, -5.0785e+01, -4.9153e+01, -4.7633e+01,\n",
       "          -4.6211e+01, -4.4876e+01, -4.3617e+01, -4.2426e+01, -4.1296e+01],\n",
       "         [-4.0221e+01, -3.9196e+01, -3.8217e+01, -3.7280e+01, -3.6380e+01,\n",
       "          -3.5516e+01, -3.4685e+01, -3.3884e+01, -3.3111e+01, -3.2364e+01,\n",
       "          -3.1642e+01, -3.0942e+01, -3.0265e+01, -2.9607e+01, -2.8968e+01,\n",
       "          -2.8348e+01, -2.7744e+01, -2.7157e+01, -2.6585e+01, -2.6027e+01],\n",
       "         [-2.5483e+01, -2.4952e+01, -2.4434e+01, -2.3927e+01, -2.3432e+01,\n",
       "          -2.2948e+01, -2.2474e+01, -2.2011e+01, -2.1556e+01, -2.1111e+01,\n",
       "          -2.0675e+01, -2.0247e+01, -1.9828e+01, -1.9416e+01, -1.9012e+01,\n",
       "          -1.8615e+01, -1.8225e+01, -1.7842e+01, -1.7465e+01, -1.7095e+01],\n",
       "         [-1.6731e+01, -1.6373e+01, -1.6020e+01, -1.5674e+01, -1.5332e+01,\n",
       "          -1.4996e+01, -1.4664e+01, -1.4338e+01, -1.4016e+01, -1.3699e+01,\n",
       "          -1.3387e+01, -1.3079e+01, -1.2775e+01, -1.2475e+01, -1.2180e+01,\n",
       "          -1.1888e+01, -1.1600e+01, -1.1316e+01, -1.1035e+01, -1.0758e+01],\n",
       "         [-1.0484e+01, -1.0214e+01, -9.9471e+00, -9.6832e+00, -9.4225e+00,\n",
       "          -9.1649e+00, -8.9102e+00, -8.6585e+00, -8.4096e+00, -8.1634e+00,\n",
       "          -7.9200e+00, -7.6793e+00, -7.4411e+00, -7.2055e+00, -6.9724e+00,\n",
       "          -6.7417e+00, -6.5135e+00, -6.2875e+00, -6.0639e+00, -5.8425e+00],\n",
       "         [-5.6233e+00, -5.4063e+00, -5.1914e+00, -4.9785e+00, -4.7677e+00,\n",
       "          -4.5589e+00, -4.3521e+00, -4.1472e+00, -3.9441e+00, -3.7430e+00,\n",
       "          -3.5436e+00, -3.3460e+00, -3.1502e+00, -2.9561e+00, -2.7638e+00,\n",
       "          -2.5730e+00, -2.3839e+00, -2.1965e+00, -2.0106e+00, -1.8262e+00],\n",
       "         [-1.6434e+00, -1.4621e+00, -1.2823e+00, -1.1039e+00, -9.2699e-01,\n",
       "          -7.5147e-01, -5.7732e-01, -4.0455e-01, -2.3313e-01, -6.3013e-02,\n",
       "           1.0579e-01,  2.7330e-01,  4.3955e-01,  6.0457e-01,  7.6835e-01,\n",
       "           9.3092e-01,  1.0923e+00,  1.2525e+00,  1.4116e+00,  1.5695e+00]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PriceInstanceNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten(start_dim = 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        flattened_x = self.flatten(x)\n",
    "        log_x = torch.log(flattened_x)\n",
    "        mean = torch.mean(log_x ,dim = 1).unsqueeze(1).unsqueeze(1)\n",
    "        std = torch.std(log_x ,dim = 1).unsqueeze(1).unsqueeze(1)\n",
    "        processed_x = (log_x - mean)/std\n",
    "        return processed_x\n",
    "\n",
    "x = torch.arange(1,141, dtype = torch.float32)\n",
    "x = x.reshape(7,4,5)\n",
    "x\n",
    "pin = PriceInstanceNorm()\n",
    "pin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb457aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimplePatch(nn.Module):\n",
    "    \"\"\"\n",
    "    简单的时间序列分段，用于输入RNN模型，因此不需要附加位置信息；\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        seq_len = x.shape[1]\n",
    "        num_channels = x.shape[2]\n",
    "        num_patch = seq_len // self.patch_size\n",
    "        effective_seq_len = num_patch * self.patch_size\n",
    "        effective_x = x[:,-effective_seq_len:,:]\n",
    "        reshaped_x = effective_x.reshape(batch_size, num_patch, self.patch_size, num_channels)\n",
    "        fallten_x = reshaped_x.reshape(batch_size, num_patch, self.patch_size, num_channels)\n",
    "        return fallten_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68f36d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 5, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = SimplePatch(patch_size = 5)\n",
    "x = torch.zeros(size = (100,17,5))\n",
    "ss(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "743ee6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patch_LSTM(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, patch_size):\n",
    "        super().__init__()\n",
    "        self.device = 'cuda:0'\n",
    "        self.patch = SimplePatch(patch_size = patch_size)\n",
    "        self.process = nn.GRU(\n",
    "            input_size = input_size * patch_size,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            dropout = dropout,\n",
    "            batch_first = True,\n",
    "            # nonlinearity='relu',\n",
    "        )\n",
    "        self.regularization = nn.Sequential(nn.Flatten(),nn.Dropout(dropout))\n",
    "        self.output = HybridDecoder(dim_state = hidden_size, init_prob = [0.0,0.5,0.0])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #为了提升模型的泛化能力，我们每次输入都随机舍弃一部分前端的序列\n",
    "        if self.training:\n",
    "            seq_len = x.shape[1]\n",
    "            random_drop = np.random.randint(0, seq_len//2)\n",
    "            x = x[:,random_drop:,:] \n",
    "\n",
    "        # patch\n",
    "        x = self.patch(x)\n",
    "\n",
    "        # lstm\n",
    "        x = self.process(x)[0][:,-1,:]\n",
    "        \n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d657b04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ferdinand\\.conda\\envs\\future\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Animator data has been reset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 25, got 45",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     27\u001b[39m train.train_set = train_set_2\n\u001b[32m     28\u001b[39m train.validation_set = validation_set_2\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m prediction, precision = \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mepoch_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m result[i,j,\u001b[32m0\u001b[39m] = prediction\n\u001b[32m     32\u001b[39m result[i,j,\u001b[32m1\u001b[39m] = precision\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\future\\Index_Future_Prediction\\utils\\model_train.py:79\u001b[39m, in \u001b[36mModelTrain.epoch_train\u001b[39m\u001b[34m(self, epochs, round, early_stop)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_epoch == \u001b[32m0\u001b[39m:\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# 如果当前模型刚刚初始化，执行一次测试记录初始损失\u001b[39;00m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mself\u001b[39m.graph.reset()\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     train_loss, train_summary, train_score = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_train\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_set\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m     validation_loss, validation_summary, validation_score = \u001b[38;5;28mself\u001b[39m.round(\u001b[38;5;28mround\u001b[39m = \u001b[38;5;28mround\u001b[39m, is_train=\u001b[38;5;28;01mFalse\u001b[39;00m, use_set=\u001b[33m'\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     81\u001b[39m     losses.append(validation_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\future\\Index_Future_Prediction\\utils\\model_train.py:59\u001b[39m, in \u001b[36mModelTrain.round\u001b[39m\u001b[34m(self, round, is_train, use_set, print_summary)\u001b[39m\n\u001b[32m     56\u001b[39m batch_data = current_set(batch_size = \u001b[38;5;28mself\u001b[39m.batch_size)\n\u001b[32m     57\u001b[39m batch_x, batch_y = batch_data[:-\u001b[32m1\u001b[39m], batch_data[-\u001b[32m1\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m pred = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m loss = \u001b[38;5;28mself\u001b[39m.loss_fn(pred, batch_y)\n\u001b[32m     61\u001b[39m losses.append(loss.item()) \n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ferdinand\\.conda\\envs\\future\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ferdinand\\.conda\\envs\\future\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mPatch_LSTM.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     27\u001b[39m x = \u001b[38;5;28mself\u001b[39m.patch(x)\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# lstm\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m][:,-\u001b[32m1\u001b[39m,:]\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ferdinand\\.conda\\envs\\future\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ferdinand\\.conda\\envs\\future\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ferdinand\\.conda\\envs\\future\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1392\u001b[39m, in \u001b[36mGRU.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1387\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1388\u001b[39m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[32m   1389\u001b[39m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[32m   1390\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1394\u001b[39m     result = _VF.gru(\n\u001b[32m   1395\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1396\u001b[39m         hx,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1403\u001b[39m         \u001b[38;5;28mself\u001b[39m.batch_first,\n\u001b[32m   1404\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ferdinand\\.conda\\envs\\future\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:364\u001b[39m, in \u001b[36mRNNBase.check_forward_args\u001b[39m\u001b[34m(self, input, hidden, batch_sizes)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_forward_args\u001b[39m(\n\u001b[32m    362\u001b[39m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]\n\u001b[32m    363\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m     expected_hidden_size = \u001b[38;5;28mself\u001b[39m.get_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[32m    367\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_hidden_size(hidden, expected_hidden_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ferdinand\\.conda\\envs\\future\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:315\u001b[39m, in \u001b[36mRNNBase.check_input\u001b[39m\u001b[34m(self, input, batch_sizes)\u001b[39m\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    312\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minput must have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_input_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m dimensions, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.dim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    313\u001b[39m     )\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.input_size != \u001b[38;5;28minput\u001b[39m.size(-\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    316\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.input_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m.size(-\u001b[32m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    317\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: input.size(-1) must be equal to input_size. Expected 25, got 45"
     ]
    }
   ],
   "source": [
    "result = np.zeros(shape = (10, len(assets_list), 4))\n",
    "\n",
    "for i in range(10):\n",
    "    validation_start, test_start, test_end = get_random_split(train_ratio, validation_ratio, test_ratio)\n",
    "    train_set, validation_set, test_set = get_data_set(assets_list, validation_start, test_start, test_end, seq_len, pred_len, threshold_ratio)\n",
    "\n",
    "    for j in range(len(assets_list)):\n",
    "        code = assets_list[j]\n",
    "        train_set_2, validation_set_2, test_set_2 = get_data_set([code], validation_start, test_start, test_end, seq_len, pred_len, threshold_ratio)\n",
    "\n",
    "        model = Patch_LSTM(input_size = 5, hidden_size = hidden_size, num_layers = num_layers, dropout = 0.5, patch_size = 5).to('cuda:0')\n",
    "        loss_fn = HybridLoss(alpha = 1e-1, delta = 1)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay = 1e-1)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n",
    "        train = ModelTrain(model = model,\n",
    "                        batch_size = 100,\n",
    "                        train_set = train_set,\n",
    "                        validation_set = validation_set,\n",
    "                        test_set = test_set,\n",
    "                        loss_fn = loss_fn,\n",
    "                        optimizer = optimizer,\n",
    "                        scheduler=scheduler,\n",
    "                        recorder=recorder,\n",
    "                        graph=animator,\n",
    "                        )\n",
    "        \n",
    "        train.train_set = train_set_2\n",
    "        train.validation_set = validation_set_2\n",
    "\n",
    "        prediction, precision = train.epoch_train(epochs = 10, round = 100, early_stop = 10)\n",
    "        result[i,j,0] = prediction\n",
    "        result[i,j,1] = precision\n",
    "\n",
    "        # prediction, precision = train.epoch_train(epochs = 10, round = 100, early_stop = 10)\n",
    "        # result[i,j,2] = prediction\n",
    "        # result[i,j,3] = precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835ec50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden_size: 10, num_layers: 1, seq_len: 20\n",
      "| stage_1_prediction   | stage_2_prediction   | stage_1_precision   | stage_2_precision   | stage_1_precision_std   | stage_2_precision_std   |\n",
      "|:---------------------|:---------------------|:--------------------|:--------------------|:------------------------|:------------------------|\n",
      "| 79.8%                | 0.0%                 | 7.3%                | 0.0%                | 23.3%                   | 0.0%                    |\n",
      "| 54.4%                | 0.0%                 | 9.1%                | 0.0%                | 27.6%                   | 0.0%                    |\n",
      "| 65.7%                | 0.0%                 | 4.6%                | 0.0%                | 13.5%                   | 0.0%                    |\n"
     ]
    }
   ],
   "source": [
    "all_assets = pd.DataFrame({\n",
    "    'stage_1_prediction': np.mean(result, axis = 0)[:,0],\n",
    "    'stage_2_prediction': np.mean(result, axis = 0)[:,2],\n",
    "\n",
    "    'stage_1_precision': np.mean(result, axis = 0)[:,1],\n",
    "    'stage_2_precision': np.mean(result, axis = 0)[:,3],\n",
    "\n",
    "    'stage_1_precision_std': np.std(result, axis = 0)[:,1],\n",
    "    'stage_2_precision_std': np.std(result, axis = 0)[:,3],\n",
    "})\n",
    "all_assets.index = pd.Series(assets_list)\n",
    "for col in all_assets.columns:\n",
    "    all_assets[col] = all_assets[col].apply(lambda x: f\"{x:.1%}\")\n",
    "\n",
    "# 转换为Markdown\n",
    "markdown_table = all_assets.to_markdown(index=False)\n",
    "print(f'hidden_size: {hidden_size}, num_layers: {num_layers}, seq_len: {seq_len}')\n",
    "print(markdown_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7035a066",
   "metadata": {},
   "source": [
    "hidden_size: 10, num_layers: 1, seq_len: 40\n",
    "| stage_1_prediction   | stage_2_prediction   | stage_1_precision   | stage_2_precision   | stage_1_precision_std   | stage_2_precision_std   |\n",
    "|:---------------------|:---------------------|:--------------------|:--------------------|:------------------------|:------------------------|\n",
    "| 13.3%                | 0.0%                 | 5.8%                | 0.0%                | 41.2%                   | 0.0%                    |\n",
    "| 0.6%                 | 0.0%                 | 13.5%               | 0.0%                | 30.6%                   | 0.0%                    |\n",
    "| 5.5%                 | 0.0%                 | 6.4%                | 0.0%                | 24.2%                   | 0.0%                    |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
