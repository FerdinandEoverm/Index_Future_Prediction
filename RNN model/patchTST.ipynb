{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88bc4d21",
   "metadata": {},
   "source": [
    "Transformer及其衍生架构，在自然语言处理上取得了卓越的成果。但是，在将这一范式迁移到时间序列预测上来的时候，却遇到了尴尬的打不过线性模型的困难"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a60c2",
   "metadata": {},
   "source": [
    "首先我们分析一下，NLP（自然语言处理）和TSF（时间序列预测）两个问题的主要差别：\n",
    "\n",
    "1. 自然语言中的语义既存在在每个单词中，也存在在单词之间的序列关系上。一个句子完全打乱单词顺序，也能保留部分信息（尽管不那么准确）。一个还不懂语法的语言学习者，仅靠单词也可以和其他人勉强交流。但是对于时间序列，打乱顺序就意味着完全丢失信息，可以说时间序列的信息绝大部分都隐藏在序列之中。\n",
    "\n",
    "2. 自然语言的具有高度的一致性和可迁移性，常见单词和词组的含义在绝大多数语料中都是相近相似的，虽然会有一些多义词但毕竟是少数。而不同的时间序列即使出现了相同的形态，也不能说就有相似含义。例如，在金融领域，某些价格形态会包含价格趋势信息，其底层的逻辑是多空双方的博弈导致的，但是如果这样的形态出现在例如气温序列中，就不能说表示趋势性，因为底层的逻辑完全不一样。\n",
    "\n",
    "3. 自然语言的训练集非常丰富，在人类历史上积累了大量的训练语料。但由于时间序列的含义差距，每个领域的时间序列是有限的，只能使用当前研究的框架内的数据。一般资产的数据有10年以上已经是非常丰富的历史了。如果扩展序列就会面临结构和范式的变化。\n",
    "\n",
    "4. 自然语言的模式迁移非常缓慢，几乎可以忽略不记，虽然人类的语言会有所发展和变化，但是这种变化都是以数十年为单位的，在短期内改变的只会有少数词的词义，大的语法是不会改变的。但对于金融数据。概念漂移是非常常见的，时间序列的底层因素，例如次贷危机、疫情的出现很可能直接导致资产的模式完全改变，从而让历史数据的价值大打折扣，进一步加剧了数据量的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c3e3f",
   "metadata": {},
   "source": [
    "Transformer架构能在NLP上取得成功的原因，恰恰也是Transformer架构不能被直接迁移到TSF上的原因：\n",
    "\n",
    "1. RNN架构的顺序结构会影响长距离信息传递，长距离信息要么随着梯度消失，要么产生梯度爆炸。为了能顺利捕捉长距离关系，Transformer架构可以放弃了RNN架构的顺序性，转而使用并行性保护远距离信息可以顺利传播；\n",
    "\n",
    "2. 因为采用了并行架构丢失了顺序信息，Transformer架构采用位置编码补齐丢失的顺序信息。但位置编码会影响一部分原始语义信息；\n",
    "\n",
    "3. 因为训练语料足够丰富，导致位置编码的影响可以被最小化；\n",
    "\n",
    "4. 平行架构也可以充分运用算力，大幅度加速训练过程，因此可以接受更复杂的模型层数。将牺牲的部分通过更大的模型来弥补。\n",
    "\n",
    "换言之，因为自然语言的训练资料足够丰富，足以掩盖Transformer架构的缺点，充分发挥Transformer架构的优势，才使得Transformer架构得以在NLP问题上大放异彩。但反过来，在TSF问题上，Transformer架构并没有这样的优势。而其劣势，会被时间序列数据量缺乏的问题放大。Transformer架构本身就很复杂，模型的参数量越大，需要的数据集也就越大，超大的模型可以轻松记忆本就为数不多的数据集导致过拟合，必须对扩展模型保持谨慎态度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007329c",
   "metadata": {},
   "source": [
    "当然，这也并不意味着完全就不能使用Transformer架构。Transformer架构在长距离提取上仍然有优势。具体来说，如果想要充分发挥Transformer架构的优势，我们需要解决如下问题：\n",
    "\n",
    "1. 每个信息单元包含的信息要足够丰富。自然语言中每个单词的语义已经非常丰富，最新的的大语言模型单个词嵌入维度已经达到了4096甚至更高。而单个时间步的OHLCV数据的维度太小，即使扩展一些辅助信息，也很难从单个时间步得到有效信息进行相互传播。因此，单个信息单元要从时间步提升到子序列级别，比如一个长达10天的子序列，除了10天本身的价格信息以外，还能抽象出某种趋势信息，例如一小段缩量上涨、或者一小段区间的放量震荡等等。通过将多个时间步组合成一个patch的方式，模型可以变为处理一段一段的时间。同时，这样的结构也可以接入更长的历史窗口，绕开Transformer在注意力层的O(N^2)复杂度的限制。\n",
    "\n",
    "2. 用科学的方式扩展训练集，如果我们的目标是资产价格预测，那么至少训练集的范围可以扩展到其他金融资产，但不应该扩展到非金融的领域。因为价格的底层逻辑是供需关系、多空博弈。同时，还要增加额外的机制让模型理解不同资产之间的差距和联系，例如波动率、相关性、协整性等等。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d3856689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler, Adam, AdamW\n",
    "from scipy.stats import norm, t\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import os\n",
    "os.chdir('d:/future/Index_Future_Prediction')\n",
    "import tushare as ts\n",
    "pro = ts.pro_api('700c1d6015ad030ff20bf310c088243da030e6b79a2a1098d58d2614')\n",
    "\n",
    "from utils.random_split import RandomSplit, CallableDataset\n",
    "from utils.back_test import BackTest\n",
    "from utils.hybrid_loss import HybridLoss\n",
    "from utils.hybrid_decoder import HybridDecoder\n",
    "from utils.prediction_recorder import PredictionRecorder\n",
    "from utils.train_animator import TrainAnimator\n",
    "from utils.model_train import ModelTrain\n",
    "from utils.get_ohlcv import GetOHLCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f8c3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX', 'AU.SHF', 'FU.SHF', 'JM.DCE','RB.SHF','HC.SHF', 'I.DCE', 'M.DCE', 'CF.ZCE',]\n",
    "assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "928934c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 20\n",
    "pred_len = 5\n",
    "train_ratio = 0.5\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.02\n",
    "threshold_ratio = 0.25\n",
    "\n",
    "patch_size = 5\n",
    "\n",
    "hidden_size = 10\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "467c4ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceInstanceNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        log_x = torch.log(x)\n",
    "        mean = torch.mean(torch.mean(log_x ,dim = -1) ,dim = -1).unsqueeze(1).unsqueeze(1)\n",
    "        return log_x - mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0da76490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 7, 12, 45])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PatchNorm(nn.Module):\n",
    "    def __init__(self, patch_size, norm_range):\n",
    "        super().__init__()\n",
    "        self.price_instance_norm = PriceInstanceNorm()\n",
    "        self.patch_size = patch_size\n",
    "        self.norm_range = norm_range\n",
    "    \n",
    "    def forward(self, x):\n",
    "        raw_shape = x.shape[:-2]\n",
    "        seq_len = x.shape[-2]\n",
    "        num_channels = x.shape[-1]\n",
    "        num_patch = seq_len // self.patch_size\n",
    "        effective_seq_len = num_patch * self.patch_size\n",
    "\n",
    "        x = x.reshape(-1, seq_len, num_channels)\n",
    "        x = x[:,-effective_seq_len:,:]\n",
    "        x = x.reshape(-1, self.patch_size, num_channels)\n",
    "        need_norm_x = x [:,:,:self.norm_range]\n",
    "        noneed_norm_x = x [:,:,self.norm_range:]\n",
    "        x = self.price_instance_norm(need_norm_x)\n",
    "        x = torch.concat((x, noneed_norm_x), dim = -1)\n",
    "        x = x.reshape(*raw_shape, num_patch, self.patch_size * num_channels)\n",
    "        return x\n",
    "\n",
    "x = torch.ones(size = (100,7,60,9))\n",
    "pin = PatchNorm(5, 4)\n",
    "pin(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bf5d7aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2855, 3, 9]), torch.Size([2855, 3, 4]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = []\n",
    "label = []\n",
    "feature_columns = ['open', 'high', 'low', 'close', 'log_open','log_high','log_low','log_close','log_amount']\n",
    "label_columns = ['label_return','down_prob','middle_prob','up_prob']\n",
    "\n",
    "for asset_code in assets_list:\n",
    "    data = pd.read_csv(f'data/{asset_code}.csv')\n",
    "    feature.append(torch.tensor(data[feature_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "    label.append(torch.tensor(data[label_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "\n",
    "feature = torch.stack(feature, dim = 1)\n",
    "label = torch.stack(label, dim = 1)\n",
    "\n",
    "feature.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed7a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 120\n",
    "patch_size = 12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c164f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2826, 3, 30, 9]), torch.Size([2826, 3, 4]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature = feature.unfold(dimension = 0, size = seq_len, step = 1).permute(0,1,3,2)\n",
    "label = label[seq_len-1:]\n",
    "feature.shape, label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a65999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.require_grad = False\n",
    "\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5cf261",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskPretrain(nn.Module):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
