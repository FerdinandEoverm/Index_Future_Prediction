{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525e132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('d:/future/Index_Future_Prediction')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler, Adam, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import optuna\n",
    "from utils import *\n",
    "from modules.truncate import SequenceTruncate\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ee6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline_LSTM(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_1, dropout_2, dropout_3):\n",
    "        super(Baseline_LSTM, self).__init__()\n",
    "        self.device = 'cuda:0'\n",
    "        self.hidden_size = hidden_size\n",
    "        self.truncate = SequenceTruncate(dropout_1)\n",
    "        self.process = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            dropout = dropout_2,\n",
    "            batch_first = True,\n",
    "            # nonlinearity='relu',\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Dropout(dropout_3),\n",
    "            HybridDecoder(dim_state = hidden_size, init_prob = [0.0,0.5,0.0])\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #为了提升模型的泛化能力，我们每次输入都随机舍弃一部分前端的序列\n",
    "        front_shape = x.shape[:-2]\n",
    "        x = self.truncate(x)\n",
    "        x = torch.flatten(x, 0, -3)\n",
    "        x = self.process(x)[0][:,-1,:]\n",
    "        x = x.reshape(*front_shape, self.hidden_size)\n",
    "        return self.output(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29a86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "    batch_size = 256\n",
    "    # seq_len = trial.suggest_categorical(\"seq_len\", [5, 10, 20, 30, 40, 50])\n",
    "    seq_len = 40\n",
    "    # hidden_size = trial.suggest_categorical(\"hidden_size\", [5, 10, 15, 20])\n",
    "    hidden_size = 20\n",
    "    num_layers = 2\n",
    "\n",
    "    # dropout_1 = trial.suggest_float(\"dropout_1\", 0.0, 0.5)\n",
    "    dropout_1 = 0.4000424120139219\n",
    "    # dropout_2 = trial.suggest_float(\"dropout_2\", 0.0, 0.5)\n",
    "    dropout_2 = 0.44103361424212434\n",
    "    # dropout_3 = trial.suggest_float(\"dropout_3\", 0.0, 0.5)\n",
    "    dropout_3 = 0.077393986849798\n",
    "    # alpha = trial.suggest_float(\"alpha\", 0.01, 0.05)\n",
    "    alpha = 0.036621336657518835\n",
    "    # weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log = True)\n",
    "    weight_decay = 0.00033605754563435157\n",
    "    # learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log = True)\n",
    "    learning_rate = 0.00027340764978690926\n",
    "    \n",
    "\n",
    "    # 提取数据\n",
    "    feature_columns = ['inday_chg_open','inday_chg_high','inday_chg_low','inday_chg_close','inday_chg_amplitude', 'ma_10','ma_26','ma_45','ma_90','ma_vol',]\n",
    "    label_columns = ['label_return','down_prob','middle_prob','up_prob']\n",
    "    assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX', 'AU.SHF', 'JM.DCE','RB.SHF','HC.SHF', 'I.DCE', 'M.DCE', 'CF.ZCE',]\n",
    "    assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX',]\n",
    "    feature = []\n",
    "    label = []\n",
    "\n",
    "    for asset_code in assets_list:\n",
    "        data = pd.read_csv(f'data/{asset_code}.csv')\n",
    "        feature.append(torch.tensor(data[feature_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "        label.append(torch.tensor(data[label_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "\n",
    "    # 加载数据\n",
    "    feature = torch.stack(feature, dim = 1)\n",
    "    label = torch.stack(label, dim = 1)\n",
    "    # print('load shape', feature.shape, label.shape)\n",
    "\n",
    "    # 折叠时间步\n",
    "    feature = feature.unfold(dimension = 0, size = seq_len, step = 1).transpose(2,3)\n",
    "    label = label[seq_len-1:]\n",
    "    # print('fold shape', feature.shape, label.shape)\n",
    "\n",
    "    data = RandomLoader(feature, label)\n",
    "    recorder = PredictionRecorder()\n",
    "    animator = TrainMonitor(figsize=(12,6))\n",
    "\n",
    "    result = np.zeros(shape = (10, len(assets_list), 4))\n",
    "    precision_list = []\n",
    "\n",
    "\n",
    "    result = []\n",
    "    for i in range(10):\n",
    "        j = 0\n",
    "        train_loader, test_loader = data(batch_size=batch_size, slice_size=[0.6, 0.2], balance=[True, False])\n",
    "\n",
    "        # for x, y in test_loader:\n",
    "        #     print(torch.sum((y[:,0]>0).float()))\n",
    "        #     raise ValueError\n",
    "        \n",
    "        animator.reset()\n",
    "        loss_fn = HybridLoss(alpha = alpha, delta = 1.3, show_loss = False) #控制损失在1：3左右\n",
    "        model = Baseline_LSTM(input_size = 10,\n",
    "                              hidden_size = hidden_size,\n",
    "                              num_layers = num_layers,\n",
    "                              dropout_1 = dropout_1,\n",
    "                              dropout_2 = dropout_2,\n",
    "                              dropout_3 = dropout_3,\n",
    "                              ).to('cuda:0')\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "        train = ModelTrain(model = model,\n",
    "                    train_loader = train_loader,\n",
    "                    test_loader = test_loader,\n",
    "                    loss_fn = loss_fn,\n",
    "                    optimizer = optimizer,\n",
    "                    scheduler = scheduler,\n",
    "                    recorder = recorder,\n",
    "                    graph = animator,\n",
    "                    )\n",
    "        prediction, precision = train.epoch_train(epochs = 10, early_stop = 100)\n",
    "\n",
    "        precision_list.append(precision)\n",
    "\n",
    "\n",
    "    return np.mean(precision_list)/np.std(precision_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06684a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=1)  # 运行30次试验\n",
    "\n",
    "print(\"最佳试验的编号: \", study.best_trial.number)\n",
    "print(\"最佳准确率: \", study.best_value)\n",
    "print(\"最佳超参数: \", study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f735d6a9",
   "metadata": {},
   "source": [
    "最佳试验的编号:  198\n",
    "最佳准确率:  2.9247318372349413\n",
    "最佳超参数:  {'batch_size': 256, 'seq_len': 40, 'hidden_size': 20, 'dropout_1': 0.4000424120139219, 'dropout_2': 0.44103361424212434, 'dropout_3': 0.077393986849798, 'alpha': 0.036621336657518835, 'weight_decay': 0.00033605754563435157, 'learning_rate': 0.00027340764978690926}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "batch_size = 256\n",
    "# seq_len = trial.suggest_categorical(\"seq_len\", [5, 10, 20, 30, 40, 50])\n",
    "seq_len = 40\n",
    "# hidden_size = trial.suggest_categorical(\"hidden_size\", [5, 10, 15, 20])\n",
    "hidden_size = 20\n",
    "num_layers = 2\n",
    "\n",
    "# dropout_1 = trial.suggest_float(\"dropout_1\", 0.0, 0.5)\n",
    "dropout_1 = 0.4000424120139219\n",
    "# dropout_2 = trial.suggest_float(\"dropout_2\", 0.0, 0.5)\n",
    "dropout_2 = 0.44103361424212434\n",
    "# dropout_3 = trial.suggest_float(\"dropout_3\", 0.0, 0.5)\n",
    "dropout_3 = 0.077393986849798\n",
    "# alpha = trial.suggest_float(\"alpha\", 0.01, 0.05)\n",
    "alpha = 0.036621336657518835\n",
    "# weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log = True)\n",
    "weight_decay = 0.00033605754563435157\n",
    "# learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log = True)\n",
    "learning_rate = 0.00027340764978690926\n",
    "    \n",
    "\n",
    "# 提取数据\n",
    "feature_columns = ['inday_chg_open','inday_chg_high','inday_chg_low','inday_chg_close','inday_chg_amplitude', 'ma_10','ma_26','ma_45','ma_90','ma_vol',]\n",
    "label_columns = ['label_return','down_prob','middle_prob','up_prob']\n",
    "assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX', 'AU.SHF', 'JM.DCE','RB.SHF','HC.SHF', 'I.DCE', 'M.DCE', 'CF.ZCE',]\n",
    "assets_list = ['IH.CFX', 'IF.CFX', 'IC.CFX',]\n",
    "feature = []\n",
    "label = []\n",
    "\n",
    "for asset_code in assets_list:\n",
    "    data = pd.read_csv(f'data/{asset_code}.csv')\n",
    "    feature.append(torch.tensor(data[feature_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "    label.append(torch.tensor(data[label_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "\n",
    "# 加载数据\n",
    "feature = torch.stack(feature, dim = 1)\n",
    "label = torch.stack(label, dim = 1)\n",
    "# print('load shape', feature.shape, label.shape)\n",
    "\n",
    "# 折叠时间步\n",
    "feature = feature.unfold(dimension = 0, size = seq_len, step = 1).transpose(2,3)\n",
    "label = label[seq_len-1:]\n",
    "# print('fold shape', feature.shape, label.shape)\n",
    "\n",
    "data = RandomLoader(feature, label)\n",
    "recorder = PredictionRecorder()\n",
    "animator = TrainMonitor(figsize=(12,6))\n",
    "\n",
    "result = np.zeros(shape = (10, len(assets_list), 4))\n",
    "precision_list = []\n",
    "\n",
    "\n",
    "result = np.zeros(shape = (10, len(assets_list), 4))\n",
    "\n",
    "for i in range(10):\n",
    "    j = 0\n",
    "    train_loader, test_loader = data(batch_size=batch_size, slice_size=[0.6, 0.2], balance=[True, False])\n",
    "\n",
    "        \n",
    "    animator.reset()\n",
    "    loss_fn = HybridLoss(alpha = alpha, delta = 1.3, show_loss = False) #控制损失在1：3左右\n",
    "    model = Baseline_LSTM(input_size = 10,\n",
    "                              hidden_size = hidden_size,\n",
    "                              num_layers = num_layers,\n",
    "                              dropout_1 = dropout_1,\n",
    "                              dropout_2 = dropout_2,\n",
    "                              dropout_3 = dropout_3,\n",
    "                              ).to('cuda:0')\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "    train = ModelTrain(model = model,\n",
    "                    train_loader = train_loader,\n",
    "                    test_loader = test_loader,\n",
    "                    loss_fn = loss_fn,\n",
    "                    optimizer = optimizer,\n",
    "                    scheduler = scheduler,\n",
    "                    recorder = recorder,\n",
    "                    graph = animator,\n",
    "                    )\n",
    "    prediction, precision = train.epoch_train(epochs = 10, early_stop = 100)\n",
    "\n",
    "    result[i,j,0] = prediction\n",
    "    result[i,j,1] = precision\n",
    "\n",
    "all_assets = pd.DataFrame({\n",
    "    'stage_1_prediction': np.mean(result, axis = 0)[:,0],\n",
    "    'stage_2_prediction': np.mean(result, axis = 0)[:,2],\n",
    "\n",
    "    'stage_1_precision': np.mean(result, axis = 0)[:,1],\n",
    "    'stage_2_precision': np.mean(result, axis = 0)[:,3],\n",
    "\n",
    "    'stage_1_precision_std': np.std(result, axis = 0)[:,1],\n",
    "    'stage_2_precision_std': np.std(result, axis = 0)[:,3],\n",
    "})\n",
    "all_assets.index = pd.Series(assets_list)\n",
    "for col in all_assets.columns:\n",
    "    all_assets[col] = all_assets[col].apply(lambda x: f\"{x:.1%}\")\n",
    "\n",
    "# 转换为Markdown\n",
    "markdown_table = all_assets.to_markdown(index=False)\n",
    "print(f'hidden_size: {hidden_size}, num_layers: {num_layers}, seq_len: {seq_len}')\n",
    "print(markdown_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
