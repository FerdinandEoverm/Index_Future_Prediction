{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9fb9502",
   "metadata": {},
   "source": [
    "二、训练模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c55e5b7",
   "metadata": {},
   "source": [
    "由于金融数据的噪声占比实在是过大，模型在学习到有效特征之前，很容易被噪声影响。其中最重要对结果产生影响的就是训练数据的选择范围。\n",
    "\n",
    "由于时序数据必须强制保证训练集在前，测试集在后，我们通过固定测试集、验证集大小，随机选择训练集起点的方式，给训练过程注入随机性，防止模型过拟合单一数据集，无法迁移到其他数据上的问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1246836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "data = pd.read_csv('data/market_state.csv', index_col='Unnamed: 0')\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "feature_column = ['near_maturity','on', 'm1', 'y1', 'y10',]\n",
    "for index in ['ic']:\n",
    "    feature_column.append(f'change_{index}')\n",
    "    feature_column.append(f'amount_{index}')\n",
    "    feature_column.append(f'near_discount_{index}')\n",
    "    feature_column.append(f'far_discount_{index}')\n",
    "    feature_column.append(f'%_diff_{index}_1')\n",
    "    feature_column.append(f'%_diff_{index}_5')\n",
    "    feature_column.append(f'%_diff_{index}_20')\n",
    "    feature_column.append(f'%_diff_{index}_60')\n",
    "\n",
    "    feature_column.append(f'MACD_{index}')\n",
    "    feature_column.append(f'RS_{index}')\n",
    "    feature_column.append(f'RSI_{index}')\n",
    "    feature_column.append(f'ATR_{index}')\n",
    "for i in feature_column:\n",
    "    data[i] = (data[i]-data[i].mean()) / data[i].std() \n",
    "feature = data[feature_column].copy()\n",
    "\n",
    "hist_len = 30\n",
    "INPUT_SIZE = len(feature_column)\n",
    "\n",
    "x = np.lib.stride_tricks.sliding_window_view(feature, window_shape = hist_len, axis = 0, writeable=True)\n",
    "x = torch.tensor(x, dtype = torch.float32, device='cuda:0').transpose(1,2)\n",
    "y = data[['label_ic_ch_next_week', 'label_volatility_ic_week']][hist_len-1:].values\n",
    "y = torch.tensor(y, dtype = torch.float32, device='cuda:0')\n",
    "\n",
    "train_size = 500\n",
    "test_size = 250\n",
    "validation_size = 250\n",
    "\n",
    "split = np.random.randint(train_size, len(feature) - test_size - validation_size) #　固定验证集和测试集大小之后，随机选择划分方式。之所以选择向后划分，是为了能通过随机载入位置，形成多种的训练集和测试集形态\n",
    "\n",
    "x_train = x[:split].to('cuda:0')\n",
    "y_train = y[:split].to('cuda:0')\n",
    "\n",
    "x_test = x[split:split+test_size].to('cuda:0')\n",
    "y_test = y[split:split+test_size].to('cuda:0')\n",
    "\n",
    "x_validation = x[split+test_size:split+test_size+validation_size].to('cuda:0')\n",
    "y_validation = y[split+test_size:split+test_size+validation_size].to('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1568018d",
   "metadata": {},
   "source": [
    "此外，在训练过程中还容易存在一个问题：当训练集数据本身具有趋势时，由于模型较为复杂，很容易导致模型记住这种趋势，从而给出有偏的预期。\n",
    "\n",
    "例如，当随机选择的训练集处在一个下跌趋势中，训练出来的模型对绝大部分样本都会给出偏负面的预期。\n",
    "\n",
    "因为模型记住了训练的下跌趋势，这样对于模型而言，无脑预测下跌就可以减少损失。\n",
    "\n",
    "为了防止这种情况，我们需要再每次前向传播和反向传播的时候，保证模型学习到等量的两个方向的数据，即在每个batch内进行标签的均衡\n",
    "\n",
    "对此我们定义了BalanceDataLoader类，在将训练数据封装进类中之后，可以通过get_batch_data方法得到均衡好的小批量训练数据；\n",
    "\n",
    "而在测试集上，也可以通过指定balance=False来模拟模型面对真实的有趋势的市场下的表现。\n",
    "\n",
    "此外，实例化BalanceDataLoader时，也可以指定 discrete=True 来生成用于分类训练的离散变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c0eddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class BalanceDataLoader():\n",
    "    \"\"\"\n",
    "    均衡的数据加载器，在训练时生成标签均衡的batch data\n",
    "    \"\"\"\n",
    "    def __init__(self, x, y, discrete = False, threshold = 0):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.length = len(y)\n",
    "        self.discrete = discrete\n",
    "        self.threshold = threshold\n",
    "    \n",
    "\n",
    "    def random_index(self, direction = None, max_attempts=1000):\n",
    "        \n",
    "        attempts = 0\n",
    "        while attempts < max_attempts:\n",
    "            random_index = np.random.randint(0, self.length)\n",
    "            if (self.y[random_index].item() > 0) == direction:\n",
    "                return random_index\n",
    "            attempts += 1\n",
    "        raise ValueError(f\"在 {max_attempts} 次尝试后未找到合法值\")\n",
    "    \n",
    "    def get_batch_data(self, batch_size, balance = True):\n",
    "        batched_x = []\n",
    "        batched_y = []\n",
    "\n",
    "        indexes = np.random.randint(0, self.length, batch_size)\n",
    "\n",
    "        if balance:\n",
    "            indexes = []\n",
    "            direction = True\n",
    "            for i in range(batch_size):\n",
    "                indexes.append(self.random_index(direction = direction))\n",
    "                direction = not direction\n",
    "        \n",
    "        for i in indexes:\n",
    "            batched_x.append(self.x[i])\n",
    "            batched_y.append(self.y[i])\n",
    "        \n",
    "        batched_x = torch.stack(batched_x, dim = 0)\n",
    "        batched_y = torch.stack(batched_y, dim = 0)\n",
    "\n",
    "        if self.discrete:\n",
    "            if self.threshold == 0:\n",
    "                positive = (batched_y>=0).float()\n",
    "                negative = (batched_y<0).float()\n",
    "                batched_y = torch.concat((positive, negative), dim = 1)\n",
    "            else:\n",
    "                positive = (batched_y>=self.threshold).float()\n",
    "                neutral = ((batched_y<self.threshold) & (batched_y>=-self.threshold)).float()\n",
    "                negative = (batched_y<-self.threshold).float()\n",
    "                batched_y = torch.concat((positive, neutral ,negative), dim = 1)\n",
    "        return batched_x, batched_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa22b2",
   "metadata": {},
   "source": [
    "接下来，我们定义PredictionRecorder类，用于在训练过程中记录每次训练的logits用于给下一个类输送数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3ec5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import  confusion_matrix\n",
    "\n",
    "class PredictionRecorder:\n",
    "    \"\"\"\n",
    "    记录和分析预测结果的类。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, is_logits = True):\n",
    "        self.records = pd.DataFrame(columns=[\n",
    "            'pred_neg', 'pred_abstain', 'pred_pos',\n",
    "            'logit_neg', 'logit_abstain', 'logit_pos',\n",
    "            'real', 'predicted_class'\n",
    "        ])\n",
    "        self.is_logits = is_logits\n",
    "\n",
    "    def add(self, predict: torch.Tensor, real: torch.Tensor):\n",
    "        if predict.shape[0] != real.shape[0]:\n",
    "            raise ValueError(\"预测张量和真实值张量的batch_size必须相同。\")\n",
    "        if predict.dim() != 2 or predict.shape[1] != 3:\n",
    "            raise ValueError(\"预测张量的形状必须是 (batch_size, 3)。\")\n",
    "        if real.dim() != 2 or real.shape[1] != 1:\n",
    "            raise ValueError(\"真实值张量的形状必须是 (batch_size, 1)。\")\n",
    "\n",
    "        if self.is_logits :\n",
    "            prob = torch.softmax(predict, dim = 1).cpu().detach().numpy()\n",
    "            logits = predict.cpu().detach().numpy()\n",
    "        else:\n",
    "            prob = predict.cpu().detach().numpy()\n",
    "            logits = torch.log(predict + 1e-9).cpu().detach().numpy()\n",
    "        \n",
    "        predicted_class = torch.argmax(predict, dim=1).cpu().detach().numpy()\n",
    "\n",
    "        new_records_df = pd.DataFrame({\n",
    "            'pred_neg': prob[:, 0],\n",
    "            'pred_abstain': prob[:, 1],\n",
    "            'pred_pos': prob[:, 2],\n",
    "            'logit_neg': logits[:, 0],\n",
    "            'logit_abstain': logits[:, 1],\n",
    "            'logit_pos': logits[:, 2],\n",
    "            'real': real.squeeze().cpu().detach().numpy(),\n",
    "            'predicted_class': predicted_class,\n",
    "        })\n",
    "        self.records = pd.concat([self.records, new_records_df], ignore_index=True)\n",
    "\n",
    "    def clear(self):\n",
    "        self.__init__()\n",
    "\n",
    "    def summary(self, threshold: float = 0.0) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Generates and prints a detailed classification performance summary DataFrame.\n",
    "        \"\"\"\n",
    "        if self.records.empty:\n",
    "            print(\"记录为空，无法生成摘要。\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        # 1. Classify 'real' values\n",
    "        def classify_real(value):\n",
    "            if value < -abs(threshold): return 0\n",
    "            elif value > abs(threshold): return 2\n",
    "            else: return 1\n",
    "\n",
    "        y_true = self.records['real'].apply(classify_real)\n",
    "        y_pred = self.records['predicted_class']\n",
    "\n",
    "        # 2. FIX: Explicitly convert dtypes to int to avoid the ValueError\n",
    "        y_true = y_true.astype(int)\n",
    "        y_pred = y_pred.astype(int)\n",
    "        \n",
    "        # 3. Compute confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
    "        \n",
    "        # (The rest of the method remains unchanged)\n",
    "        results = []\n",
    "        for i in range(3):\n",
    "            tp = cm[i, i]\n",
    "            predicted_count = cm[:, i].sum()\n",
    "            true_count = cm[i, :].sum()\n",
    "            precision = tp / predicted_count if predicted_count > 0 else 0\n",
    "            recall = tp / true_count if true_count > 0 else 0\n",
    "            severe_error = 0\n",
    "            if i == 0:\n",
    "                severe_error = cm[2, 0] / predicted_count if predicted_count > 0 else 0\n",
    "            elif i == 2:\n",
    "                severe_error = cm[0, 2] / predicted_count if predicted_count > 0 else 0\n",
    "            results.append({\n",
    "                '预测为该分类的个数': predicted_count,\n",
    "                'Precision (精确率)': precision,\n",
    "                '真实为该分类的个数': true_count,\n",
    "                'Accuracy (召回率)': recall,\n",
    "                'Severe (严重错误率)': severe_error\n",
    "            })\n",
    "\n",
    "        total_samples = cm.sum()\n",
    "        total_correct = np.trace(cm)\n",
    "        total_severe_errors = cm[2, 0] + cm[0, 2]\n",
    "        overall_accuracy = total_correct / total_samples if total_samples > 0 else 0\n",
    "        overall_severe_rate = total_severe_errors / total_samples if total_samples > 0 else 0\n",
    "        results.append({\n",
    "            '预测为该分类的个数': total_samples,\n",
    "            'Precision (精确率)': overall_accuracy,\n",
    "            '真实为该分类的个数': total_samples,\n",
    "            'Accuracy (召回率)': overall_accuracy,\n",
    "            'Severe (严重错误率)': overall_severe_rate\n",
    "        })\n",
    "        summary_df = pd.DataFrame(results, index=['分类 0 (负)', '分类 1 (放弃)', '分类 2 (正)', '总计'])\n",
    "        # print(f\"--- 基于阈值 {threshold} 的分类性能摘要 ---\")\n",
    "        # print(summary_df.to_string(float_format=\"%.4f\"))\n",
    "        return summary_df\n",
    "\n",
    "    def distribution(self) -> tuple[float, float, float]:\n",
    "        if self.records.empty:\n",
    "            return (0.0, 0.0, 0.0)\n",
    "        props = self.records['predicted_class'].value_counts(normalize=True).reindex([0, 1, 2]).fillna(0)\n",
    "        return (props[0], props[1], props[2])\n",
    "\n",
    "    def average_score(self) -> tuple[float, float, float]:\n",
    "        \"\"\"\n",
    "        计算三个分类的 logits 的全局平均值。\n",
    "\n",
    "        返回:\n",
    "            tuple[float, float, float]: 一个包含三个浮点数的元组，\n",
    "                                        分别代表 logit_neg, logit_abstain, logit_pos 的平均值。\n",
    "                                        如果没有任何记录，则返回 (0.0, 0.0, 0.0)。\n",
    "        \"\"\"\n",
    "        if self.records.empty:\n",
    "            return (0.0, 0.0, 0.0)\n",
    "\n",
    "        # 选取 logits 相关的列\n",
    "        logit_columns = ['logit_neg', 'logit_abstain', 'logit_pos']\n",
    "        \n",
    "        # 使用 .mean() 计算每列的平均值\n",
    "        avg_logits = self.records[logit_columns].mean()\n",
    "\n",
    "        return (avg_logits['logit_neg'], avg_logits['logit_abstain'], avg_logits['logit_pos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11d8240",
   "metadata": {},
   "source": [
    "PredictionRecorder.distribution() 和 PredictionRecorder.average_score()方法用于向Animator传递prob 和 logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e66dec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "\n",
    "class Animator:\n",
    "    \"\"\"在动画中绘制数据，用于在模型训练中动态监控损失、预测概率、logits的变化。\"\"\"\n",
    "\n",
    "    def __init__(self, figsize=(12, 6)):\n",
    "        self.num_subplots = 6\n",
    "        self.reset()\n",
    "        self.fig, self.axes = plt.subplots(2, 3, figsize=figsize)\n",
    "        self.axes = self.axes.flatten()\n",
    "        titles = ['train loss', 'train classes prob', 'train classes logits', 'test loss', 'test classes prob', 'test classes logits']\n",
    "        for i, ax in enumerate(self.axes):\n",
    "            ax.set_title(titles[i])\n",
    "            ax.grid()\n",
    "        self.fig.tight_layout()\n",
    "\n",
    "    def add(self, x, y, subplot_idx=0):\n",
    "        \"\"\"\n",
    "        向指定的子图添加数据点。\n",
    "        参数:\n",
    "            x : 当前epoch\n",
    "            y : 记录的值，对于prob和logits，传入元组\n",
    "            subplot_idx (int): 子图的编号\n",
    "        \"\"\"\n",
    "        if subplot_idx < 0 or subplot_idx >= self.num_subplots:\n",
    "            raise ValueError(f\"subplot_idx must be between 0 and {self.num_subplots - 1}.\")\n",
    "            \n",
    "        target_plot = self.data[subplot_idx]\n",
    "        \n",
    "        # 确保y是列表\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        # 确保x是列表\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "            \n",
    "        # 第一次添加数据时需要初始化\n",
    "        if not target_plot['X']:\n",
    "            target_plot['X'] = [[] for _ in range(n)]\n",
    "            target_plot['Y'] = [[] for _ in range(n)]\n",
    "\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                target_plot['X'][i].append(a)\n",
    "                target_plot['Y'][i].append(b)\n",
    "\n",
    "        self.draw()\n",
    "\n",
    "    def draw(self):\n",
    "        \"\"\"绘制子图\"\"\"\n",
    "        display.clear_output(wait=True)\n",
    "        for i, ax in enumerate(self.axes):\n",
    "            ax.cla()\n",
    "            plot_data = self.data[i]\n",
    "            if plot_data['X']:\n",
    "                fmts = ('-', 'm--', 'g-.', 'r:')\n",
    "                for j in range(len(plot_data['X'])):\n",
    "                    ax.plot(plot_data['X'][j], plot_data['Y'][j], fmts[j % len(fmts)])\n",
    "            ax.legend()\n",
    "        self.fig.tight_layout()\n",
    "        display.display(self.fig)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"清空数据\"\"\"\n",
    "        self.data = [{'X': [], 'Y': []} for _ in range(self.num_subplots)]\n",
    "        print(\"Animator data has been reset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e82ce",
   "metadata": {},
   "source": [
    "最后，将所有的训练过程封装进训练循环中\n",
    "\n",
    "需要向循环内传递：\n",
    "\n",
    "1. BalanceDataLoader封装的训练集、测试集；\n",
    "\n",
    "2. 实例化的损失函数；\n",
    "\n",
    "3. 实例化的优化器；\n",
    "\n",
    "4. 实例化的学习率调度器；\n",
    "\n",
    "5. PredictionRecorder实例化的recorder\n",
    "\n",
    "6. Animator实例化的graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7fa6022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import torch\n",
    "\n",
    "def round_train(model, data_set, loss_fn, optimizer, is_train, round, recorder):\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    sum_loss = 0\n",
    "    recorder.clear()\n",
    "    if is_train:\n",
    "        for i in tqdm.tqdm(range(round)):\n",
    "            batch_x, batch_y = data_set.get_batch_data(batch_size = 100, balance = True)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch_x)\n",
    "            loss = loss_fn(pred, batch_y)\n",
    "            sum_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1.0)\n",
    "            optimizer.step()\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            for i in range(round):\n",
    "                batch_x, batch_y = data_set.get_batch_data(batch_size = 100, balance = True)\n",
    "                pred = model(batch_x)\n",
    "                loss = loss_fn(pred, batch_y)\n",
    "                sum_loss += loss.item()\n",
    "    return sum_loss/round\n",
    "\n",
    "def epoch_train_test(model,train_set, test_set, loss_fn, optimizer, scheduler ,epochs, graph, recorder, continue_train = 0):\n",
    "    if continue_train == 0:\n",
    "        graph.reset()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        current_epoch = epoch + 1 + continue_train\n",
    "        train_loss = round_train(model = model, data_set = train_set, loss_fn = loss_fn, optimizer = optimizer, is_train = True, round = 100, recorder = recorder)\n",
    "        test_loss = round_train(model = model, data_set = test_set, loss_fn = loss_fn, optimizer = optimizer, is_train = False, round = 100, recorder = recorder)\n",
    "\n",
    "        scheduler.step()\n",
    "        graph.add(current_epoch, train_loss, subplot_idx = 0)\n",
    "        graph.add(current_epoch, test_loss, subplot_idx = 3)\n",
    "        graph.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
