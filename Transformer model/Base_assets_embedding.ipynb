{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d4a1378",
   "metadata": {},
   "source": [
    "Patch TST 模型是假设通道独立的，所谓通道独立，就是把每个时间序列都当作独立的时间序列，把面板数据降维到时间序列级别，再说难听一点就是忽略截面关系。这样的选择有一定道理，因为首先其实绝大部分时间序列的关系确实是微弱的，建模截面关系只会徒增复杂度，效果并不好，为过拟合控制带来额外的成本\n",
    "\n",
    "这样的假设导致了我们在训练输出层的时候，不能把所有的资产都加入到训练中，只能一个板块训练，然后用于预测一个板块，不同板块的资产，其变化模式的差异较大，只用单一输出层拟合所有资产带来的损失过大。\n",
    "\n",
    "但是金融市场的资产相关性是很强的，对于期货市场而言，既可以发掘板块内高相似性资产的套利关系，也可以发掘股指期货、国债期货、商品期货和贵金属期货、农产品期货的板块轮动关系，抛弃掉这样的关系未免太可惜了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d80a5e",
   "metadata": {},
   "source": [
    "对此，我提出一种强相关性资产截面建模的模式，可以同时起到数据增强和因子挖掘的效果：\n",
    "\n",
    "1. 定义一组可以多空交易的资产，称为基资产，基资产之间最好有较强的统计关系，覆盖面要足够广\n",
    "\n",
    "2. 任意基资产的多空组合（实际中控制多空比例和总仓位）称为组合资产。传统对于时间序列数据不足的问题有方法通过人工生成数据，但这些数据现实中不存在，对模型的指导意义存疑。由于期货市场的特性，组合资产是实在可交易的一种切实存在的金融资产，避免了传统人工生成的数据缺少实际意义的问题。\n",
    "\n",
    "3. 基资产也可以视为一个特殊的组合资产（单资产比例为100%）\n",
    "\n",
    "4. 定义一个可学习的嵌入，将每种基资产嵌入到高维空间的一个向量\n",
    "\n",
    "5. 任意组合资产的嵌入向量即使其基资产的高维嵌入的线性组合。例如假设C的嵌入是（0.2，0.3，0.5...） M的嵌入是（0.8，0.6，0.1...），则 70%C+30%M 的组合资产（饲料）的嵌入即为（0.28，0.39，0.36...）\n",
    "\n",
    "6. 到这里其实已经很接近传统模型了，嵌入的各个维度实际上就是某种“因子”，或者说某种方向的 Risk Exposure，例如利率、通胀等等。一个投资组合的风险暴露或其它特性理应是其成分资产风险暴露的加权平均。这种结构化的约束或称归纳偏置使得嵌入空间的学习更加高效和有意义，避免了模型学到毫无逻辑的表征。\n",
    "\n",
    "7. 组合资产同样有价格时间序列，也有了嵌入表示，我们就可以将生成的组合资产加入到训练集中，大大弥补训练数据不足的问题；\n",
    "\n",
    "8. 而且这样的模式是端到端的。，传统因子模型需要先验地定义因子（如市值、估值）。而维度不是预先定义的，而是模型学习出来的，比人为定义更科学，甚至可能能发现新的因子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceaffad",
   "metadata": {},
   "source": [
    "下一个问题就是，如何预训练这个assets embedding呢？还是回到原假设，投资组合的风险暴露是其成分资产风险暴露的加权平均。\n",
    "\n",
    "由于基资产之间不可能是完全正交的，任意一种基资产应当可以被其他资产线性表出。我们随机选择一个基资产At当作组合资产，然后以其他基资产(A1,A2...)作为基向量，通过求解线性方程组的形式，得到一个目标基资产的线性组合表出：\n",
    "\n",
    "At = f1 * A1 + f2 * A2....\n",
    "\n",
    "然后我们随机选取一个时间段，计算这个时间段内每个资产的年化收益率，用(A1,A2...)的收益率与权重估计At的收益率，然后与真实的At收益率对比，计算L1 loss 并反向传播，更新embedding 的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1574f5",
   "metadata": {},
   "source": [
    "当然，由于维度小于资产总数，线性表出的方式不止一种，我们希望的是找到其中权重参数绝对值最小的一组，即线性方程组的最小范数解。\n",
    "\n",
    "同时为了提高效率，我们可以同时选取多个目标基资产，虽然能找到的最小范数解并不一定是最优，但执行效率更高，可以向量化处理，解出伪逆矩阵就可以得到最小范数解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9563bda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding              : torch.Size([10, 30])\n",
      "target                 : torch.Size([10, 5])\n",
      "base                   : torch.Size([10, 25])\n",
      "pseudoinverse          : torch.Size([25, 10])\n",
      "minimized norm solution: torch.Size([25, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = 'cuda:0'\n",
    "\n",
    "# 总资产数 = 30，维度 = 10，目标资产 = 5\n",
    "A_embedding = torch.randn(size = (10, 30), device=device)\n",
    "\n",
    "# 根据随机数选择目标资产\n",
    "target_indices = torch.randperm(30, device=device)[:5]\n",
    "A_target = A_embedding[:, target_indices]\n",
    "\n",
    "# 剩余部分作为基向量\n",
    "mask = torch.ones(30, dtype=torch.bool, device=device)\n",
    "mask[target_indices] = False\n",
    "A_base = A_embedding[:, mask]\n",
    "\n",
    "# 解出伪逆矩阵\n",
    "A_base_pinv = torch.linalg.pinv(A_base)\n",
    "\n",
    "# 最小范数解即为\n",
    "X = A_base_pinv @ A_target\n",
    "\n",
    "print(f\"embedding              : {A_embedding.shape}\")\n",
    "print(f\"target                 : {A_target.shape}\")\n",
    "print(f\"base                   : {A_base.shape}\")\n",
    "print(f\"pseudoinverse          : {A_base_pinv.shape}\")\n",
    "print(f\"minimized norm solution: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0acbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4]) torch.Size([32, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class AssetsEmbedding(nn.Module):\n",
    "    def __init__(self, num_assets, embedding_dim, target_ratio = 0.2):\n",
    "        super().__init__()\n",
    "        self.num_assets = num_assets\n",
    "        self.embedding_dim  = embedding_dim\n",
    "        \n",
    "\n",
    "        # 设置目标资产的比例\n",
    "        self.num_target = math.ceil((num_assets - embedding_dim) * target_ratio)\n",
    "        \n",
    "\n",
    "        self.embedding = nn.Embedding(num_embeddings = num_assets, embedding_dim = embedding_dim, max_norm = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "    \n",
    "    def pre_train(self, x):\n",
    "        \"\"\"\n",
    "        预训练，现在每次输入的x是一个批次的收益率数据\n",
    "        x 的形状: (batch_size, num_assets)\n",
    "        返回: x_pred, x_real, 形状均为 (batch_size, 5)\n",
    "        \"\"\"\n",
    "        # 对于整个批次，我们选择相同的目标和基准资产\n",
    "        # 索引目标资产和基准资产\n",
    "        target_indices = torch.randperm(self.num_assets, device = x.device)[:self.num_target]\n",
    "        mask = torch.ones(self.num_assets, dtype=torch.bool, device = x.device)\n",
    "        mask[target_indices] = False\n",
    "\n",
    "        # 分离预测目标和基向量的嵌入\n",
    "        A_target = self.embedding.weight[target_indices]\n",
    "        A_base = self.embedding.weight[mask]\n",
    "\n",
    "        # 求解方程组，这个 solution 矩阵对于整个批次是通用的\n",
    "        solution = torch.linalg.lstsq(A_base.T, A_target.T).solution\n",
    "        \n",
    "        # 映射线性关系到批次的收益率上\n",
    "        # 从批次数据中选取所有样本的目标资产真实收益率\n",
    "        # x 形状 (batch_size, 30) -> x_real 形状 (batch_size, 5)\n",
    "        x_real = x[:, target_indices] \n",
    "\n",
    "        # 从批次数据中选取所有样本的基准资产真实收益率\n",
    "        # x 形状 (batch_size, 30) -> x_base 形状 (batch_size, 25)\n",
    "        x_base = x[:, mask]\n",
    "\n",
    "        # x_base (batch_size, 25) @ solution (25, 5) -> x_pred (batch_size, 5)\n",
    "        x_pred = x_base @ solution \n",
    "        \n",
    "        return x_pred, x_real\n",
    "\n",
    "model =  AssetsEmbedding(30, 10).to('cuda:0')\n",
    "loss_fn = nn.L1Loss()\n",
    "x = torch.randn(size = (32, 30), device = 'cuda:0')\n",
    "x_pred, x_real = model.pre_train(x)\n",
    "print(x_pred.shape, x_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678525b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b745bed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_list = [\n",
    "    # 黑色金属产业链\n",
    "    'I.DCE', 'JM.DCE', 'RB.SHF', 'HC.SHF', 'SS.SHF', 'SF.ZCE', 'SM.ZCE',\n",
    "    # 有色金属\n",
    "    'CU.SHF', 'AL.SHF', 'ZN.SHF', 'NI.SHF',\n",
    "    # 贵金属\n",
    "    'AU.SHF', 'AG.SHF',\n",
    "    # 能源化工\n",
    "    'FU.SHF', 'LU.INE', 'BU.SHF', 'PG.DCE', 'TA.ZCE', 'EG.DCE', 'PF.ZCE', \n",
    "    'L.DCE', 'PP.DCE', 'V.DCE', 'EB.DCE', 'MA.ZCE', 'UR.ZCE', 'RU.SHF',\n",
    "    # 农产品\n",
    "    'A.DCE', 'B.DCE', 'M.DCE', 'Y.DCE', 'RM.ZCE', 'OI.ZCE', 'P.DCE', 'PK.ZCE',\n",
    "    'C.DCE', 'CS.DCE', 'CF.ZCE', 'SR.ZCE', 'CJ.ZCE', 'AP.ZCE', 'SP.SHF', \n",
    "    'JD.DCE', 'LH.DCE',\n",
    "    # 建材\n",
    "    'FG.ZCE', 'SA.ZCE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c271a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_names = [\n",
    "    # 黑色金属\n",
    "    '铁矿石', '焦煤', '螺纹钢', '热轧卷板', '不锈钢', '硅铁', '锰硅',\n",
    "    # 有色金属\n",
    "    '沪铜', '沪铝', '沪锌', '沪镍',\n",
    "    # 贵金属\n",
    "    '黄金', '白银',\n",
    "    # 能源化工\n",
    "    '燃油', '低硫燃料油', '沥青', 'LPG', 'PTA', '乙二醇', '短纤', \n",
    "    '塑料', '聚丙烯', 'PVC', '苯乙烯', '甲醇', '尿素', '橡胶',\n",
    "    # 农产品\n",
    "    '豆一', '豆二', '豆粕', '豆油', '菜粕', '菜油', '棕榈油', '花生',\n",
    "    '玉米', '玉米淀粉', '棉花', '白糖', '红枣', '苹果', '纸浆', \n",
    "    '鸡蛋', '生猪',\n",
    "    # 建材\n",
    "    '玻璃', '纯碱'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561da75b",
   "metadata": {},
   "source": [
    "选取标准为上市历史超过1000个交易日，且最近100个交易日主力合约日均持仓量大于50000。交易持仓量过小的合约可能陷入流动性问题，且其成交量往往也比较小，价格不够透明，滑点交易成本也比较高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c529035",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('d:/future/Index_Future_Prediction')\n",
    "\n",
    "import yaml\n",
    "with open('config.yaml', 'r') as file:\n",
    "    token = yaml.safe_load(file)['token']\n",
    "\n",
    "import tushare as ts\n",
    "pro = ts.pro_api(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25f8c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取日收益率数据\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "daily_yield = []\n",
    "for assets_code in assets_list:\n",
    "    data = pro.fut_daily(ts_code = assets_code, start_date = '20210202', fields = 'trade_date, pre_close, close')\n",
    "    assets_daily_yield = np.log(data['close']) - np.log(data['pre_close'])\n",
    "    daily_yield.append(torch.tensor(assets_daily_yield.values, device = 'cuda:0', dtype = torch.float32))\n",
    "\n",
    "daily_yield = torch.stack(daily_yield, dim = 0)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_yield = daily_yield[:,:800]\n",
    "test_yield = daily_yield[:,800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e396e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 212/10000 [00:19<03:53, 41.94it/s]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "num_assets = len(assets_list)\n",
    "embedding_dim = 10\n",
    "target_ratio = 0.5\n",
    "learning_rate = 1e-5\n",
    "weight_decay = 1e-5\n",
    "\n",
    "\n",
    "minimize_window = 5\n",
    "train_sample_range = train_yield.shape[1]\n",
    "test_sample_range = test_yield.shape[1]\n",
    "\n",
    "model = AssetsEmbedding(num_assets = num_assets, embedding_dim = embedding_dim, target_ratio = target_ratio).to('cuda:0')\n",
    "loss_fn = nn.HuberLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(),lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "\n",
    "def batch(train_batch_size = 128, test_batch_size = 32):\n",
    "\n",
    "    # 测试\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch_yield = []\n",
    "\n",
    "        begin = np.random.randint(0, test_sample_range - minimize_window, test_batch_size)\n",
    "        end = np.array([np.random.randint(first+minimize_window,test_sample_range) for first in begin])\n",
    "        # end = np.array([first+minimize_window for first in begin])\n",
    "\n",
    "\n",
    "        for i in range(test_batch_size):\n",
    "            range_yield = test_yield[:, begin[i]: end[i]]\n",
    "            target_yield = torch.mean(range_yield, dim = 1)\n",
    "            batch_yield.append(target_yield)\n",
    "        batch_yield = torch.stack(batch_yield)\n",
    "        x_pred, x_real = model.pre_train(batch_yield)\n",
    "        test_loss = loss_fn(x_pred, x_real)\n",
    "\n",
    "    # 训练\n",
    "    model.train()\n",
    "    batch_yield = []\n",
    "\n",
    "    begin = np.random.randint(0, train_sample_range - minimize_window, train_batch_size)\n",
    "    end = np.array([np.random.randint(first+minimize_window, train_sample_range) for first in begin])\n",
    "    # end = np.array([first+minimize_window for first in begin])\n",
    "\n",
    "    for i in range(train_batch_size):\n",
    "        range_yield = train_yield[:, begin[i]: end[i]]\n",
    "        target_yield = torch.mean(range_yield, dim = 1)\n",
    "        batch_yield.append(target_yield)\n",
    "    batch_yield = torch.stack(batch_yield)\n",
    "\n",
    "    x_pred, x_real = model.pre_train(batch_yield)\n",
    "    optimizer.zero_grad()\n",
    "    train_loss = loss_fn(x_pred, x_real)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return train_loss.cpu().detach(), test_loss.cpu().detach()\n",
    "\n",
    "def train(round):\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i in tqdm.tqdm(range(round)):\n",
    "        train_loss, test_loss = batch(train_batch_size = 128, test_batch_size = 128)\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "\n",
    "    plt.plot(range(round), train_losses)\n",
    "    plt.plot(range(round), test_losses)\n",
    "    plt.show()\n",
    "\n",
    "train(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd62e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.embedding.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2064ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 2. 计算所有向量两两之间的余弦相似度\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "# 3. 使用 aeborn 的 heatmap 进行可视化\n",
    "#    为了显示更清晰，我们用 Pandas DataFrame 包装一下，并加上资产名称作为索引\n",
    "similarity_df = pd.DataFrame(similarity_matrix, index=assets_names, columns=assets_names)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "# 使用中文显示需要设置字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 或者你系统中的任何中文字体\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.heatmap(similarity_df, cmap='viridis', annot=False) # annot=True 可以显示数值，但资产多时会很乱\n",
    "plt.title('资产嵌入向量的余弦相似度热力图')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# --- PCA 可视化 ---\n",
    "pca = PCA(n_components=2) # 降到2维\n",
    "embeddings_pca = pca.fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embeddings_pca[:, 0], embeddings_pca[:, 1])\n",
    "\n",
    "# 在图上为每个点添加资产名称标签\n",
    "for i, name in enumerate(assets_names):\n",
    "    plt.annotate(name, (embeddings_pca[i, 0], embeddings_pca[i, 1]))\n",
    "\n",
    "plt.title('资产嵌入向量 PCA 降维可视化')\n",
    "plt.xlabel('第一主成分')\n",
    "plt.ylabel('第二主成分')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- t-SNE 可视化 ---\n",
    "# perplexity 值通常在5-50之间，可以把它看作是每个点邻居的数量\n",
    "tsne = TSNE(n_components=2, perplexity=5, random_state=42)\n",
    "embeddings_tsne = tsne.fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(embeddings_tsne[:, 0], embeddings_tsne[:, 1])\n",
    "\n",
    "# 在图上为每个点添加资产名称标签\n",
    "for i, name in enumerate(assets_names):\n",
    "    plt.annotate(name, (embeddings_tsne[i, 0], embeddings_tsne[i, 1]))\n",
    "\n",
    "plt.title('资产嵌入向量 t-SNE 降维可视化')\n",
    "plt.xlabel('t-SNE aomponent 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "future",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
