{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88bc4d21",
   "metadata": {},
   "source": [
    "Transformer及其衍生架构，在自然语言处理上取得了卓越的成果。但是，在将这一范式迁移到时间序列预测上来的时候，却遇到了尴尬的打不过线性模型的困难"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a60c2",
   "metadata": {},
   "source": [
    "首先我们分析一下，NLP（自然语言处理）和TSF（时间序列预测）两个问题的主要差别：\n",
    "\n",
    "1. 自然语言中的语义既存在在每个单词中，也存在在单词之间的序列关系上。一个句子完全打乱单词顺序，也能保留部分信息（尽管不那么准确）。一个还不懂语法的语言学习者，仅靠单词也可以和其他人勉强交流。但是对于时间序列，打乱顺序就意味着完全丢失信息，可以说时间序列的信息绝大部分都隐藏在序列之中。\n",
    "\n",
    "2. 自然语言的具有高度的一致性和可迁移性，常见单词和词组的含义在绝大多数语料中都是相近相似的，虽然会有一些多义词但毕竟是少数。而不同的时间序列即使出现了相同的形态，也不能说就有相似含义。例如，在金融领域，某些价格形态会包含价格趋势信息，其底层的逻辑是多空双方的博弈导致的，但是如果这样的形态出现在例如气温序列中，就不能说表示趋势性，因为底层的逻辑完全不一样。\n",
    "\n",
    "3. 自然语言的训练集非常丰富，在人类历史上积累了大量的训练语料。但由于时间序列的含义差距，每个领域的时间序列是有限的，只能使用当前研究的框架内的数据。一般资产的数据有10年以上已经是非常丰富的历史了。如果扩展序列就会面临结构和范式的变化。\n",
    "\n",
    "4. 自然语言的模式迁移非常缓慢，几乎可以忽略不记，虽然人类的语言会有所发展和变化，但是这种变化都是以数十年为单位的，在短期内改变的只会有少数词的词义，大的语法是不会改变的。但对于金融数据。概念漂移是非常常见的，时间序列的底层因素，例如次贷危机、疫情的出现很可能直接导致资产的模式完全改变，从而让历史数据的价值大打折扣，进一步加剧了数据量的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6c3e3f",
   "metadata": {},
   "source": [
    "Transformer架构能在NLP上取得成功的原因，恰恰也是Transformer架构不能被直接迁移到TSF上的原因：\n",
    "\n",
    "1. RNN架构的顺序结构会影响长距离信息传递，长距离信息要么随着梯度消失，要么产生梯度爆炸。为了能顺利捕捉长距离关系，Transformer架构可以放弃了RNN架构的顺序性，转而使用并行性保护远距离信息可以顺利传播；\n",
    "\n",
    "2. 因为采用了并行架构丢失了顺序信息，Transformer架构采用位置编码补齐丢失的顺序信息。但位置编码会影响一部分原始语义信息；\n",
    "\n",
    "3. 因为训练语料足够丰富，导致位置编码的影响可以被最小化；\n",
    "\n",
    "4. 平行架构也可以充分运用算力，大幅度加速训练过程，因此可以接受更复杂的模型层数。将牺牲的部分通过更大的模型来弥补。\n",
    "\n",
    "换言之，因为自然语言的训练资料足够丰富，足以掩盖Transformer架构的缺点，充分发挥Transformer架构的优势，才使得Transformer架构得以在NLP问题上大放异彩。但反过来，在TSF问题上，Transformer架构并没有这样的优势。而其劣势，会被时间序列数据量缺乏的问题放大。Transformer架构本身就很复杂，模型的参数量越大，需要的数据集也就越大，超大的模型可以轻松记忆本就为数不多的数据集导致过拟合，必须对扩展模型保持谨慎态度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007329c",
   "metadata": {},
   "source": [
    "当然，这也并不意味着完全就不能使用Transformer架构。Transformer架构在长距离提取上仍然有优势。具体来说，如果想要充分发挥Transformer架构的优势，我们需要解决如下问题：\n",
    "\n",
    "1. 每个信息单元包含的信息要足够丰富。自然语言中每个单词的语义已经非常丰富，最新的的大语言模型单个词嵌入维度已经达到了4096甚至更高。而单个时间步的OHLCV数据的维度太小，即使扩展一些辅助信息，也很难从单个时间步得到有效信息进行相互传播。因此，单个信息单元要从时间步提升到子序列级别，比如一个长达10天的子序列，除了10天本身的价格信息以外，还能抽象出某种趋势信息，例如一小段缩量上涨、或者一小段区间的放量震荡等等。通过将多个时间步组合成一个patch的方式，模型可以变为处理一段一段的时间。同时，这样的结构也可以接入更长的历史窗口，绕开Transformer在注意力层的O(N^2)复杂度的限制。\n",
    "\n",
    "2. 用科学的方式扩展训练集，如果我们的目标是资产价格预测，那么至少训练集的范围可以扩展到其他金融资产，但不应该扩展到非金融的领域。因为价格的底层逻辑是供需关系、多空博弈。同时，还要增加额外的机制让模型理解不同资产之间的差距和联系，例如波动率、相关性、协整性等等。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3856689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('d:/future/Index_Future_Prediction')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import optuna\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler, Adam, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a65999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    处理(* , seq_len, feature_dim) tensor，在seq_len维度上添加位置编码。\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, dropout, max_len = 5000):\n",
    "        \"\"\"\n",
    "            d_model (int): 特征维度 (feature_dim)\n",
    "            dropout (float): Dropout的概率\n",
    "            max_len (int): 预先计算编码的最大序列长度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        assert d_model % 2 == 0, \"d_model 必须是偶数\"\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "\n",
    "\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(-2)\n",
    "        pos_encoding = self.pe[:seq_len, :]\n",
    "        x = x + pos_encoding\n",
    "        return self.dropout(x)\n",
    "    \n",
    "class PatchProjection(nn.Module):\n",
    "    def __init__(self, input_size, patch_size, d_model = 128, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        self.project = nn.Linear(input_size * patch_size, d_model) # 暂时只使用单层线性投影就够了 暂时不需要做太过深度的信息抽象，这个过程会交给Encoder去完成\n",
    "        self.pe = PositionalEncoding(d_model = d_model, dropout = dropout)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.project(x)\n",
    "        x = self.pe(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3c757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.patch import TimeSeriesPatcher\n",
    "from modules.encoder import MultiLayerEncoder\n",
    "\n",
    "\n",
    "class Patch_TST(nn.Module):\n",
    "    \"\"\"循环神经网络模型\"\"\"\n",
    "    def __init__(self, input_size, seq_len, patch_size, stride, num_layer, num_head, d_model, masking_ratio, dropout_1, dropout_2, dropout_3):\n",
    "        super().__init__()\n",
    "        self.device = 'cuda:0'\n",
    "        self.input_size = input_size\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.masking_ratio = masking_ratio\n",
    "\n",
    "        self.num_patch = int(np.floor((seq_len - patch_size) / stride) + 1)\n",
    "\n",
    "        self.patch = TimeSeriesPatcher(patch_size, stride) # 首先经过patcher分成子序列\n",
    "\n",
    "        self.projection = PatchProjection(input_size, patch_size, d_model = d_model, dropout = dropout_1)\n",
    "\n",
    "        self.encoder = MultiLayerEncoder(dim_feature = d_model, dim_sequence = self.num_patch, num_enc_layer = num_layer, num_head = num_head, num_ffn_hidden = d_model*2, dropout = dropout_2)\n",
    "\n",
    "        self.reconstruction = nn.Linear(d_model, input_size * patch_size)\n",
    "        \n",
    "        self.output = nn.Sequential(\n",
    "            nn.Flatten(start_dim = -2),\n",
    "            nn.Dropout(dropout_3),\n",
    "            HybridDecoder(dim_state = self.num_patch * d_model, init_prob = [0.0,0.5,0.0])\n",
    "        )\n",
    "    \n",
    "    # 自监督学习\n",
    "    def self_supervised(self, x):\n",
    "        \n",
    "        device = x.device\n",
    "        batch_size = x.shape[0]\n",
    "        noise = torch.rand(size = (batch_size, self.num_patch)).to(device)\n",
    "        mask = noise < self.masking_ratio\n",
    "        reshape_mask = mask.unsqueeze(-1)\n",
    "\n",
    "        x_patched = self.patch(x)\n",
    "        \n",
    "        x_masked = torch.where(reshape_mask, 0.0, x_patched)\n",
    "        x_projected = self.projection(x_masked)\n",
    "        x_encodered = self.encoder(x_projected)\n",
    "        x_pre_reconstruction = x_encodered[mask]\n",
    "        x_reconstructed = self.reconstruction(x_pre_reconstruction)\n",
    "        x_target = x_patched[mask]\n",
    "\n",
    "        return x_reconstructed, x_target\n",
    "    \n",
    "    # 传播输出\n",
    "    def forward(self, x):\n",
    "        x_patched = self.patch(x)\n",
    "        x_projected = self.projection(x_patched)\n",
    "        x_encodered = self.encoder(x_projected)\n",
    "        output = self.output(x_encodered)\n",
    "        return output\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2107fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "\n",
    "    # 超参数\n",
    "    seq_len = trial.suggest_int(\"seq_len\", 30, 120)\n",
    "    patch_size = trial.suggest_int(\"patch_size\", 5, 30)\n",
    "\n",
    "    num_layer = trial.suggest_categorical('num_layer', [1,2,3])\n",
    "    num_head = trial.suggest_categorical('num_head', [4,8,16])\n",
    "    d_model = trial.suggest_categorical('d_model', [64,128,256])\n",
    "    \n",
    "\n",
    "    dropout_1 = trial.suggest_float(\"dropout_1\", 0.0, 0.5)\n",
    "    dropout_2 = trial.suggest_float(\"dropout_2\", 0.0, 0.5)\n",
    "    dropout_3 = 0.2\n",
    "\n",
    "    batch_size = trial.suggest_categorical('batch_size', [64,128,256])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"learning_rate\", 1e-6, 1e-3, log=True)\n",
    "\n",
    "    assets_list_all = ['IH.CFX', 'IF.CFX', 'IC.CFX', 'AU.SHF', 'JM.DCE','RB.SHF','HC.SHF', 'I.DCE', 'M.DCE', 'CF.ZCE',]\n",
    "    assets_list_cfx = ['IH.CFX', 'IF.CFX', 'IC.CFX',]\n",
    "    assets_list = trial.suggest_categorical(\"assets_list\", [assets_list_all, assets_list_cfx])\n",
    "\n",
    "    # 预训练目标 这两个超参数是比较特殊的，不能随机选择\n",
    "    # 掩码的比例是预训练的难度，随机选择这个参数不公平\n",
    "    # 步长则关系到模型能从前后的序列中偷看到多少的的信息，对预训练也至关重要\n",
    "    \n",
    "    stride = patch_size # no overlap\n",
    "    masking_ratio = 0.2 # 可以设置较小的遮蔽率，因为模型完全不能偷看，只要遮蔽率是固定的，对其他超参数选择就是公平的\n",
    "\n",
    "\n",
    "    # 提取数据\n",
    "    feature_columns = ['inday_chg_open','inday_chg_high','inday_chg_low','inday_chg_close','inday_chg_amplitude', 'ma_10','ma_26','ma_45','ma_90','ma_vol',]\n",
    "    label_columns = ['label_return','down_prob','middle_prob','up_prob']\n",
    "\n",
    "    \n",
    "    # 加载数据\n",
    "    feature = []\n",
    "    label = []\n",
    "    for asset_code in assets_list:\n",
    "        data = pd.read_csv(f'data/{asset_code}.csv')\n",
    "        feature.append(torch.tensor(data[feature_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "        label.append(torch.tensor(data[label_columns].values, dtype = torch.float32, device = 'cuda:0'))\n",
    "\n",
    "    feature = torch.stack(feature, dim = 1)\n",
    "    label = torch.stack(label, dim = 1)\n",
    "    feature = feature.unfold(dimension = 0, size = seq_len, step = 1).transpose(2,3)\n",
    "    label = label[seq_len-1:]\n",
    "    data = RandomLoader(feature, label)\n",
    "    train_loader, test_loader = data(batch_size=batch_size, slice_size=[0.5,0.4], balance=[True, False])\n",
    "\n",
    "\n",
    "\n",
    "    loss_fn = nn.MSELoss()\n",
    "    model = Patch_TST(input_size = 10,\n",
    "                    seq_len = seq_len,\n",
    "                    patch_size = patch_size,\n",
    "                    stride = stride,\n",
    "                    num_layer = num_layer, \n",
    "                    num_head = num_head,\n",
    "                    d_model = d_model,\n",
    "                    masking_ratio = masking_ratio,\n",
    "                    dropout_1 = dropout_1,\n",
    "                    dropout_2 = dropout_2,\n",
    "                    dropout_3 = dropout_3,\n",
    "                    ).to('cuda:0')\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "\n",
    "\n",
    "    def epoch():\n",
    "        train_losses = []\n",
    "        model.train()\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x_reconstructed, x_target = model.self_supervised(batch_x)\n",
    "            loss = loss_fn(x_reconstructed, x_target)\n",
    "            train_losses.append(loss.item()) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        test_losses = []\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in test_loader:\n",
    "                x_reconstructed, x_target = model.self_supervised(batch_x)\n",
    "                loss = loss_fn(x_reconstructed, x_target)\n",
    "                test_losses.append(loss.item()) \n",
    "        return np.mean(train_losses), np.mean(test_losses)\n",
    "\n",
    "    def train(epochs = 100):\n",
    "        train_losses = []\n",
    "        test_losses = []\n",
    "        for i in tqdm.tqdm(range(epochs)):\n",
    "            train_loss, test_loss = epoch()\n",
    "            train_losses.append(train_loss)\n",
    "            test_losses.append(test_loss)\n",
    "            scheduler.step()\n",
    "        # plt.plot(range(epochs), train_losses)\n",
    "        # plt.plot(range(epochs), test_losses)\n",
    "        # plt.show()\n",
    "        return np.mean(test_losses[-10:])\n",
    "\n",
    "    final_loss = train(100)\n",
    "\n",
    "    return final_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dc0b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)  # 运行30次试验\n",
    "\n",
    "\n",
    "print(\"最佳试验的编号: \", study.best_trial.number)\n",
    "print(\"最佳准确率: \", study.best_value)\n",
    "print(\"最佳超参数: \", study.best_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
